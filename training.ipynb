{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "from keras.layers import (Conv2D, BatchNormalization, Dropout, Flatten, Dense, MaxPool2D)\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare empty dictionary to store dataset (path, label, duration)\n",
    "dataset = {\n",
    "    \"paths\": [],\n",
    "    \"labels\": [],\n",
    "    \"durations\": []\n",
    "}\n",
    "\n",
    "# walk through the path and append the data to the dictionary\n",
    "for dirname, _, filenames in os.walk(\"dataset\"):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        dataset[\"paths\"].append(path)\n",
    "\n",
    "        label = filename.split(\"-\")[0]\n",
    "        dataset[\"labels\"].append(label)\n",
    "\n",
    "        duration = round(librosa.get_duration(path = path), 4)\n",
    "        dataset[\"durations\"].append(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = []\n",
    "\n",
    "# loop through the dataframe and create mfccs from the audio\n",
    "for path in dataset[\"paths\"]:\n",
    "    y, sr = librosa.load(path, sr = 22550)\n",
    "    mfcc = librosa.feature.mfcc(y = y, sr = sr, n_mfcc = 30)\n",
    "    mfccs.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_mfccs = []\n",
    "\n",
    "def resize_mfcc(array):\n",
    "    # create empty array with shape (30, 110)\n",
    "    new_mfcc = np.zeros((30, 110))\n",
    "    # loop through the array and copy the value to the new array\n",
    "    # if the mfcc length less than 110, the rest of the array will be filled with 0\n",
    "    # if the mfcc length more than 110, the rest of the array will be ignored\n",
    "    for i in range(30):\n",
    "        for j in range(110):\n",
    "            try:\n",
    "                new_mfcc[i][j] = array[i][j]\n",
    "            except IndexError:\n",
    "                pass\n",
    "    \n",
    "    # return the new resized mfcc\n",
    "    return new_mfcc\n",
    "\n",
    "for mfcc in mfccs:\n",
    "    resized_mfccs.append(resize_mfcc(mfcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_split(x, y):\n",
    "    y = y.copy()\n",
    "    # replace string label with number\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == \"sad\": y[i] = 0\n",
    "        elif y[i] == \"happy\": y[i] = 1\n",
    "\n",
    "    # copy the dataset input\n",
    "    x = x.copy()\n",
    "\n",
    "    # split the dataset into train and test set (80:20)\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(x, y, train_size = 0.8, shuffle = True, random_state = 0)\n",
    "    # split the train set into train and validation set (80:20)\n",
    "    x_tr, x_va, y_tr, y_va = train_test_split(x_tr, y_tr, test_size = 0.2, shuffle = True, random_state = 0)\n",
    "\n",
    "    # convert the dataset into numpy array\n",
    "    x_tr = np.array([i for i in x_tr])\n",
    "    x_va = np.array([i for i in x_va])\n",
    "    x_te = np.array([i for i in x_te])\n",
    "\n",
    "    # get the mean and standard deviation of the train set\n",
    "    tr_mean = np.mean(x_tr, axis = 0)\n",
    "    tr_std = np.std(x_tr, axis = 0)\n",
    "\n",
    "    # normalize the dataset\n",
    "    x_tr = (x_tr - tr_mean) / tr_std\n",
    "    x_va = (x_va - tr_mean) / tr_std\n",
    "    x_te = (x_te - tr_mean) / tr_std\n",
    "\n",
    "    # add channel dimension to the dataset\n",
    "    x_tr = x_tr[..., None]\n",
    "    x_va = x_va[..., None]\n",
    "    x_te = x_te[..., None]\n",
    "\n",
    "    # return the splitted dataset\n",
    "    return x_tr, y_tr, x_va, y_va, x_te, y_te, tr_mean, tr_std\n",
    "\n",
    "x_tr, y_tr, x_va, y_va, x_te, y_te, tr_mean, tr_std = make_train_test_split(resized_mfccs, dataset[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to create the model (CNN)\n",
    "def create_model(x_tr):\n",
    "    # create sequential model from keras\n",
    "    model = keras.Sequential()\n",
    "    # add first convolutional layer, max pooling layer, and batch normalization layer\n",
    "    model.add(Conv2D(filters = 64, kernel_size = 5, strides = (2, 2), activation = \"tanh\", input_shape = x_tr.shape[1:]))\n",
    "    model.add(MaxPool2D(pool_size = 2))\n",
    "    model.add(BatchNormalization())\n",
    "    # add second convolutional layer, max pooling layer, and batch normalization layer\n",
    "    model.add(Conv2D(filters = 32, kernel_size = 4, strides = (2, 1), activation = \"tanh\"))\n",
    "    model.add(MaxPool2D(pool_size = 2))\n",
    "    model.add(BatchNormalization())\n",
    "    # add flatten layer\n",
    "    model.add(Flatten())\n",
    "    # add first dense layer, dropout layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation = \"relu\"))\n",
    "    # add second dense layer, dropout layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation = \"relu\"))\n",
    "    # add third dense layer, dropout layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 2, activation = \"sigmoid\"))\n",
    "\n",
    "    # show the summary of the model\n",
    "    model.summary()\n",
    "\n",
    "    # return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 13, 53, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 6, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 6, 26, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 2, 23, 32)         32800     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 1, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 1, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 352)               0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 352)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 128)               45184     \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,226\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 3s 57ms/step - loss: 0.8962 - accuracy: 0.6328 - val_loss: 0.7630 - val_accuracy: 0.5094\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.6377 - accuracy: 0.7586 - val_loss: 0.7235 - val_accuracy: 0.5125\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4941 - accuracy: 0.7969 - val_loss: 0.6340 - val_accuracy: 0.5312\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.4445 - accuracy: 0.8125 - val_loss: 0.6075 - val_accuracy: 0.5656\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.3937 - accuracy: 0.8367 - val_loss: 0.5299 - val_accuracy: 0.6906\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3883 - accuracy: 0.8398 - val_loss: 0.4622 - val_accuracy: 0.7969\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 1s 38ms/step - loss: 0.3494 - accuracy: 0.8578 - val_loss: 0.4227 - val_accuracy: 0.8375\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3386 - accuracy: 0.8586 - val_loss: 0.3846 - val_accuracy: 0.8531\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.3287 - accuracy: 0.8609 - val_loss: 0.3653 - val_accuracy: 0.8469\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3113 - accuracy: 0.8773 - val_loss: 0.3439 - val_accuracy: 0.8562\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3076 - accuracy: 0.8695 - val_loss: 0.3501 - val_accuracy: 0.8625\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2756 - accuracy: 0.8930 - val_loss: 0.3314 - val_accuracy: 0.8719\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2368 - accuracy: 0.8961 - val_loss: 0.3355 - val_accuracy: 0.8656\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2321 - accuracy: 0.9094 - val_loss: 0.3397 - val_accuracy: 0.8687\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.2192 - accuracy: 0.9086 - val_loss: 0.3390 - val_accuracy: 0.8500\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2121 - accuracy: 0.9133 - val_loss: 0.3410 - val_accuracy: 0.8469\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1994 - accuracy: 0.9187 - val_loss: 0.3398 - val_accuracy: 0.8562\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 13, 53, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 6, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 6, 26, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 2, 23, 32)         32800     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 1, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 1, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 352)               0         \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 352)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 128)               45184     \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,226\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 2s 53ms/step - loss: 0.9293 - accuracy: 0.7078 - val_loss: 0.7580 - val_accuracy: 0.5656\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.4947 - accuracy: 0.7937 - val_loss: 0.5804 - val_accuracy: 0.6156\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3852 - accuracy: 0.8539 - val_loss: 0.5419 - val_accuracy: 0.6812\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3453 - accuracy: 0.8672 - val_loss: 0.4598 - val_accuracy: 0.7875\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 1s 39ms/step - loss: 0.3394 - accuracy: 0.8687 - val_loss: 0.3790 - val_accuracy: 0.8281\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3196 - accuracy: 0.8805 - val_loss: 0.4042 - val_accuracy: 0.8281\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.3311 - accuracy: 0.8750 - val_loss: 0.4092 - val_accuracy: 0.8031\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.3014 - accuracy: 0.8781 - val_loss: 0.4335 - val_accuracy: 0.8062\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 1s 47ms/step - loss: 0.2941 - accuracy: 0.8734 - val_loss: 0.3935 - val_accuracy: 0.8781\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.3071 - accuracy: 0.8867 - val_loss: 0.3678 - val_accuracy: 0.8438\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.2791 - accuracy: 0.8922 - val_loss: 0.4375 - val_accuracy: 0.8531\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.2828 - accuracy: 0.8781 - val_loss: 0.4316 - val_accuracy: 0.8562\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.2478 - accuracy: 0.9008 - val_loss: 0.4624 - val_accuracy: 0.8500\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.2677 - accuracy: 0.8898 - val_loss: 0.4375 - val_accuracy: 0.8469\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 1s 45ms/step - loss: 0.2302 - accuracy: 0.9156 - val_loss: 0.4259 - val_accuracy: 0.8313\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 13, 53, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 6, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 6, 26, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 2, 23, 32)         32800     \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 1, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 1, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 352)               0         \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 352)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 128)               45184     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,226\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 2s 105ms/step - loss: 1.0708 - accuracy: 0.5969 - val_loss: 0.6895 - val_accuracy: 0.5094\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.7236 - accuracy: 0.7305 - val_loss: 0.7085 - val_accuracy: 0.5094\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.5805 - accuracy: 0.7828 - val_loss: 0.6200 - val_accuracy: 0.5375\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.5677 - accuracy: 0.7953 - val_loss: 0.5782 - val_accuracy: 0.5938\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.4747 - accuracy: 0.7984 - val_loss: 0.5459 - val_accuracy: 0.6938\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.4745 - accuracy: 0.8062 - val_loss: 0.5138 - val_accuracy: 0.7656\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.4085 - accuracy: 0.8414 - val_loss: 0.4692 - val_accuracy: 0.8281\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.4279 - accuracy: 0.8266 - val_loss: 0.4457 - val_accuracy: 0.8469\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.3484 - accuracy: 0.8570 - val_loss: 0.4324 - val_accuracy: 0.8594\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.3682 - accuracy: 0.8484 - val_loss: 0.4200 - val_accuracy: 0.8469\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.3338 - accuracy: 0.8727 - val_loss: 0.4048 - val_accuracy: 0.8406\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 0.3136 - accuracy: 0.8727 - val_loss: 0.4020 - val_accuracy: 0.8281\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 0.3029 - accuracy: 0.8711 - val_loss: 0.3902 - val_accuracy: 0.8250\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.3111 - accuracy: 0.8797 - val_loss: 0.3871 - val_accuracy: 0.8219\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2796 - accuracy: 0.8953 - val_loss: 0.4020 - val_accuracy: 0.8000\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2866 - accuracy: 0.8867 - val_loss: 0.4082 - val_accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.2706 - accuracy: 0.8836 - val_loss: 0.3872 - val_accuracy: 0.8125\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2454 - accuracy: 0.9070 - val_loss: 0.4113 - val_accuracy: 0.8031\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 0.2578 - accuracy: 0.8945 - val_loss: 0.4553 - val_accuracy: 0.8031\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 13, 53, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 6, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_28 (Bat  (None, 6, 26, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 2, 23, 32)         32800     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 1, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_29 (Bat  (None, 1, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 352)               0         \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 352)               0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 128)               45184     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,226\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 2s 97ms/step - loss: 0.8206 - accuracy: 0.6859 - val_loss: 1.4678 - val_accuracy: 0.5094\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.4790 - accuracy: 0.8055 - val_loss: 0.6852 - val_accuracy: 0.5219\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.3901 - accuracy: 0.8133 - val_loss: 0.8370 - val_accuracy: 0.5250\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.3524 - accuracy: 0.8594 - val_loss: 0.5729 - val_accuracy: 0.6250\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.3203 - accuracy: 0.8687 - val_loss: 0.5272 - val_accuracy: 0.7219\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 0.3087 - accuracy: 0.8641 - val_loss: 0.4595 - val_accuracy: 0.7719\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.2648 - accuracy: 0.8992 - val_loss: 0.4458 - val_accuracy: 0.7937\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 1s 79ms/step - loss: 0.2747 - accuracy: 0.8766 - val_loss: 0.3730 - val_accuracy: 0.8219\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2308 - accuracy: 0.9125 - val_loss: 0.3812 - val_accuracy: 0.8313\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.2522 - accuracy: 0.8992 - val_loss: 0.3653 - val_accuracy: 0.8625\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.2107 - accuracy: 0.9180 - val_loss: 0.4454 - val_accuracy: 0.8500\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.2360 - accuracy: 0.9156 - val_loss: 0.4272 - val_accuracy: 0.8656\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 1s 81ms/step - loss: 0.2271 - accuracy: 0.9117 - val_loss: 0.4215 - val_accuracy: 0.8656\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 1s 77ms/step - loss: 0.2244 - accuracy: 0.9219 - val_loss: 0.4270 - val_accuracy: 0.8438\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.2313 - accuracy: 0.9086 - val_loss: 0.4250 - val_accuracy: 0.8438\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 13, 53, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 6, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_30 (Bat  (None, 6, 26, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 2, 23, 32)         32800     \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 1, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_31 (Bat  (None, 1, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 352)               0         \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 352)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 128)               45184     \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,226\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 56ms/step - loss: 1.0132 - accuracy: 0.6195 - val_loss: 0.6844 - val_accuracy: 0.5094\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 1s 48ms/step - loss: 0.6384 - accuracy: 0.7500 - val_loss: 0.6809 - val_accuracy: 0.5281\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.5143 - accuracy: 0.8016 - val_loss: 0.5886 - val_accuracy: 0.5938\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4397 - accuracy: 0.8195 - val_loss: 0.5203 - val_accuracy: 0.7250\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.4200 - accuracy: 0.8336 - val_loss: 0.4640 - val_accuracy: 0.7937\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3837 - accuracy: 0.8469 - val_loss: 0.4177 - val_accuracy: 0.8125\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3725 - accuracy: 0.8430 - val_loss: 0.3785 - val_accuracy: 0.8406\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3614 - accuracy: 0.8492 - val_loss: 0.3602 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.3067 - accuracy: 0.8633 - val_loss: 0.3454 - val_accuracy: 0.8562\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3064 - accuracy: 0.8648 - val_loss: 0.3475 - val_accuracy: 0.8469\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2832 - accuracy: 0.8750 - val_loss: 0.3432 - val_accuracy: 0.8562\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2633 - accuracy: 0.8953 - val_loss: 0.3589 - val_accuracy: 0.8469\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2376 - accuracy: 0.8992 - val_loss: 0.3685 - val_accuracy: 0.8375\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.2705 - accuracy: 0.8969 - val_loss: 0.3412 - val_accuracy: 0.8531\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.2173 - accuracy: 0.9023 - val_loss: 0.3542 - val_accuracy: 0.8687\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2306 - accuracy: 0.9141 - val_loss: 0.3502 - val_accuracy: 0.8687\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2203 - accuracy: 0.9094 - val_loss: 0.3271 - val_accuracy: 0.8781\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.1811 - accuracy: 0.9211 - val_loss: 0.3571 - val_accuracy: 0.8594\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.1946 - accuracy: 0.9219 - val_loss: 0.3747 - val_accuracy: 0.8562\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 1s 44ms/step - loss: 0.1611 - accuracy: 0.9352 - val_loss: 0.3692 - val_accuracy: 0.8594\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.1809 - accuracy: 0.9328 - val_loss: 0.3947 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.1446 - accuracy: 0.9477 - val_loss: 0.3769 - val_accuracy: 0.8656\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 13, 53, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 6, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 6, 26, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 2, 23, 32)         32800     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 1, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 1, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 352)               0         \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 352)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 128)               45184     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,226\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "20/20 [==============================] - 2s 50ms/step - loss: 0.9056 - accuracy: 0.7117 - val_loss: 0.9628 - val_accuracy: 0.5094\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.4911 - accuracy: 0.7883 - val_loss: 1.1557 - val_accuracy: 0.5094\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.3677 - accuracy: 0.8438 - val_loss: 0.9710 - val_accuracy: 0.5594\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 1s 42ms/step - loss: 0.3548 - accuracy: 0.8609 - val_loss: 0.5833 - val_accuracy: 0.7063\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3326 - accuracy: 0.8703 - val_loss: 0.5252 - val_accuracy: 0.7625\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.3205 - accuracy: 0.8734 - val_loss: 0.4226 - val_accuracy: 0.8219\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2844 - accuracy: 0.8945 - val_loss: 0.3663 - val_accuracy: 0.8313\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.2975 - accuracy: 0.8836 - val_loss: 0.5184 - val_accuracy: 0.8156\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3065 - accuracy: 0.8773 - val_loss: 0.3650 - val_accuracy: 0.8438\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.2715 - accuracy: 0.8969 - val_loss: 0.3416 - val_accuracy: 0.8562\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.2915 - accuracy: 0.8836 - val_loss: 0.3476 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2770 - accuracy: 0.8844 - val_loss: 0.3828 - val_accuracy: 0.8469\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2674 - accuracy: 0.8859 - val_loss: 0.3858 - val_accuracy: 0.8313\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 0.4004 - val_accuracy: 0.8406\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 1s 43ms/step - loss: 0.2843 - accuracy: 0.8867 - val_loss: 0.3239 - val_accuracy: 0.8469\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2594 - accuracy: 0.8961 - val_loss: 0.3975 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2675 - accuracy: 0.9039 - val_loss: 0.3871 - val_accuracy: 0.8625\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2722 - accuracy: 0.8914 - val_loss: 0.3789 - val_accuracy: 0.8594\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 1s 40ms/step - loss: 0.2929 - accuracy: 0.8836 - val_loss: 0.4710 - val_accuracy: 0.8500\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 1s 41ms/step - loss: 0.2921 - accuracy: 0.8891 - val_loss: 0.4079 - val_accuracy: 0.8531\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_34 (Conv2D)          (None, 13, 53, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 6, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 6, 26, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 2, 23, 32)         32800     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 1, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 1, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 352)               0         \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 352)               0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 128)               45184     \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,226\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 100ms/step - loss: 1.3279 - accuracy: 0.5750 - val_loss: 0.7057 - val_accuracy: 0.5094\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 1s 83ms/step - loss: 0.7699 - accuracy: 0.7094 - val_loss: 0.7483 - val_accuracy: 0.5094\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.5884 - accuracy: 0.7883 - val_loss: 0.6819 - val_accuracy: 0.5125\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.5808 - accuracy: 0.7945 - val_loss: 0.6064 - val_accuracy: 0.5531\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.5096 - accuracy: 0.8078 - val_loss: 0.5720 - val_accuracy: 0.6125\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.4415 - accuracy: 0.8281 - val_loss: 0.5451 - val_accuracy: 0.7125\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.4415 - accuracy: 0.8133 - val_loss: 0.5162 - val_accuracy: 0.7969\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.3932 - accuracy: 0.8328 - val_loss: 0.4839 - val_accuracy: 0.8375\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.3818 - accuracy: 0.8445 - val_loss: 0.4534 - val_accuracy: 0.8469\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 0.3578 - accuracy: 0.8562 - val_loss: 0.4359 - val_accuracy: 0.8344\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.3455 - accuracy: 0.8633 - val_loss: 0.4208 - val_accuracy: 0.8250\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.3351 - accuracy: 0.8609 - val_loss: 0.4210 - val_accuracy: 0.8156\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.3496 - accuracy: 0.8562 - val_loss: 0.4105 - val_accuracy: 0.8156\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.2998 - accuracy: 0.8711 - val_loss: 0.3962 - val_accuracy: 0.8250\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.2995 - accuracy: 0.8836 - val_loss: 0.3991 - val_accuracy: 0.8094\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.2849 - accuracy: 0.8766 - val_loss: 0.3975 - val_accuracy: 0.8125\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.2519 - accuracy: 0.8992 - val_loss: 0.4104 - val_accuracy: 0.8000\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 1s 93ms/step - loss: 0.2428 - accuracy: 0.8953 - val_loss: 0.4377 - val_accuracy: 0.7969\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.2316 - accuracy: 0.9016 - val_loss: 0.4533 - val_accuracy: 0.7875\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 13, 53, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 6, 26, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 6, 26, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 2, 23, 32)         32800     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 1, 11, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 1, 11, 32)        128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 352)               0         \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 352)               0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 128)               45184     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,418\n",
      "Trainable params: 88,226\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 2s 109ms/step - loss: 0.7853 - accuracy: 0.7195 - val_loss: 1.0166 - val_accuracy: 0.5094\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.4976 - accuracy: 0.7852 - val_loss: 0.6726 - val_accuracy: 0.5094\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.3936 - accuracy: 0.8516 - val_loss: 0.6641 - val_accuracy: 0.5531\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 1s 84ms/step - loss: 0.3532 - accuracy: 0.8484 - val_loss: 0.5494 - val_accuracy: 0.6531\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.3038 - accuracy: 0.8695 - val_loss: 0.4518 - val_accuracy: 0.7688\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.2996 - accuracy: 0.8891 - val_loss: 0.4810 - val_accuracy: 0.7281\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.2504 - accuracy: 0.8992 - val_loss: 0.4095 - val_accuracy: 0.7969\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 0.2647 - accuracy: 0.8984 - val_loss: 0.3819 - val_accuracy: 0.8438\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.2740 - accuracy: 0.8914 - val_loss: 0.3248 - val_accuracy: 0.8625\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 1s 86ms/step - loss: 0.2354 - accuracy: 0.9117 - val_loss: 0.3525 - val_accuracy: 0.8562\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 1s 85ms/step - loss: 0.1996 - accuracy: 0.9203 - val_loss: 0.3479 - val_accuracy: 0.8656\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2281 - accuracy: 0.9172 - val_loss: 0.3409 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2030 - accuracy: 0.9203 - val_loss: 0.3823 - val_accuracy: 0.8562\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.2062 - accuracy: 0.9141 - val_loss: 0.4054 - val_accuracy: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.913542</td>\n",
       "      <td>0.851042</td>\n",
       "      <td>0.210227</td>\n",
       "      <td>0.339946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.902083</td>\n",
       "      <td>0.842708</td>\n",
       "      <td>0.248580</td>\n",
       "      <td>0.441923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.895052</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.257930</td>\n",
       "      <td>0.417920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.851042</td>\n",
       "      <td>0.227586</td>\n",
       "      <td>0.424495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.938542</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.162239</td>\n",
       "      <td>0.380261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>64</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.888021</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.285735</td>\n",
       "      <td>0.419266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.898698</td>\n",
       "      <td>0.794792</td>\n",
       "      <td>0.242091</td>\n",
       "      <td>0.433788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>128</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.917188</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.212462</td>\n",
       "      <td>0.376208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch_size  learning_rate  accuracy  val_accuracy      loss  val_loss\n",
       "0     50          64          0.001  0.913542      0.851042  0.210227  0.339946\n",
       "1     50          64          0.010  0.902083      0.842708  0.248580  0.441923\n",
       "2     50         128          0.001  0.895052      0.806250  0.257930  0.417920\n",
       "3     50         128          0.010  0.914062      0.851042  0.227586  0.424495\n",
       "4    100          64          0.001  0.938542      0.858333  0.162239  0.380261\n",
       "5    100          64          0.010  0.888021      0.854167  0.285735  0.419266\n",
       "6    100         128          0.001  0.898698      0.794792  0.242091  0.433788\n",
       "7    100         128          0.010  0.917188      0.850000  0.212462  0.376208"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(x_tr, y_tr, x_va, y_va, epoch, batch_size, learning_rate):\n",
    "    # create the model\n",
    "    model = create_model(x_tr)\n",
    "    # prepare the Adam optimizer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    # compile the model\n",
    "    model.compile(optimizer = optimizer, loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "    # prepare early stopping callback\n",
    "    earlystopping_cb = keras.callbacks.EarlyStopping(patience = 5)\n",
    "\n",
    "    # train the model\n",
    "    history = model.fit(\n",
    "        x = np.asarray(x_tr),\n",
    "        y = np.asarray(y_tr),\n",
    "        epochs = epoch,\n",
    "        batch_size = batch_size,\n",
    "        validation_data = (np.asarray(x_va), np.asarray(y_va)),\n",
    "        callbacks = [earlystopping_cb]\n",
    "    )\n",
    "\n",
    "    # return the model and history\n",
    "    return model, history\n",
    "\n",
    "train_hyperparameter = {\n",
    "    \"epoch\": [50, 100],\n",
    "    \"batch_size\": [64, 128],\n",
    "    \"learning_rate\": [0.001, 0.01],\n",
    "}\n",
    "\n",
    "train_result = {\n",
    "    \"epoch\": [],\n",
    "    \"batch_size\": [],\n",
    "    \"learning_rate\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"loss\": [],\n",
    "    \"val_loss\": [],\n",
    "}\n",
    "\n",
    "for e in train_hyperparameter[\"epoch\"]:\n",
    "    for b in train_hyperparameter[\"batch_size\"]:\n",
    "        for l in train_hyperparameter[\"learning_rate\"]:\n",
    "            model, history = train(x_tr, y_tr, x_va, y_va, e, b, l)\n",
    "            joblib.dump(model, f\"model_{e}_{b}_{l}.joblib\")\n",
    "            train_result[\"epoch\"].append(e)\n",
    "            train_result[\"batch_size\"].append(b)\n",
    "            train_result[\"learning_rate\"].append(l)\n",
    "            train_result[\"accuracy\"].append(np.mean(history.history[\"accuracy\"][-3:]))\n",
    "            train_result[\"val_accuracy\"].append(np.mean(history.history[\"val_accuracy\"][-3:]))\n",
    "            train_result[\"loss\"].append(np.mean(history.history[\"loss\"][-3:]))\n",
    "            train_result[\"val_loss\"].append(np.mean(history.history[\"val_loss\"][-3:]))\n",
    "\n",
    "result_pd = pd.DataFrame(train_result)\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_index = result_pd[\"val_accuracy\"].idxmax()\n",
    "best_model_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test the model\n",
    "def test(model, x_te, y_te):\n",
    "    # evaluate the model\n",
    "    loss_te, accuracy_te = model.evaluate(np.asarray(x_te), np.asarray(y_te))\n",
    "\n",
    "    # return the loss and accuracy\n",
    "    return loss_te, accuracy_te\n",
    "\n",
    "# function to make prediction\n",
    "def make_prediction(model, x_te):\n",
    "    # make prediction from trained model\n",
    "    predictions = model.predict(np.asarray(x_te))\n",
    "\n",
    "    # prepare empty list to store the prediction\n",
    "    pred = []\n",
    "    # loop through the predictions and append the prediction to the list\n",
    "    for i in predictions:\n",
    "        pred.append(np.argmax(i))\n",
    "    \n",
    "    # return the prediction\n",
    "    return predictions, pred\n",
    "\n",
    "# function to predict the test set\n",
    "def predict(model, x_te, y_te):\n",
    "    # make prediction\n",
    "    _, pred = make_prediction(model, x_te)\n",
    "    # calculate the precision, recall, and f1 score\n",
    "    precision = precision_score(y_te, pred)\n",
    "    recall = recall_score(y_te, pred)\n",
    "    f1 = f1_score(y_te, pred)\n",
    "    \n",
    "    # return the prediction, precision, recall, and f1 score\n",
    "    return pred, precision, recall, f1\n",
    "\n",
    "# function to plot the confusion matrix\n",
    "def confusion_matrix(pred, y_te):\n",
    "    # prepare numbered labels from string labels\n",
    "    labels = {\"sad\": 0, \"happy\": 1}\n",
    "\n",
    "    # create figure and axes (left: confusion matrix (count), right: confusion matrix (ratio))\n",
    "    fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20, 8))\n",
    "\n",
    "    # plot the confusion matrix (count)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_te, pred, display_labels = labels, ax = ax[0])\n",
    "    ax[0].set_title(\"Confusion Matrix (count)\", size = 14)\n",
    "\n",
    "    # plot the confusion matrix (ratio)\n",
    "    ConfusionMatrixDisplay.from_predictions(y_te, pred, display_labels = labels, normalize = \"true\", ax = ax[1])\n",
    "    ax[1].set_title(\"Confusion Matrix (ratio)\", size = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3176 - accuracy: 0.8750\n",
      "13/13 [==============================] - 0s 7ms/step\n",
      "Loss: 0.31755220890045166\n",
      "Accuracy: 0.875\n",
      "Precision: 0.898936170212766\n",
      "Recall: 0.845\n",
      "F1 Score: 0.8711340206185567\n"
     ]
    }
   ],
   "source": [
    "selected_model = joblib.load(f\"model_{result_pd['epoch'][best_model_index]}_{result_pd['batch_size'][best_model_index]}_{result_pd['learning_rate'][best_model_index]}.joblib\")\n",
    "\n",
    "# test the model using testing data (return the loss and accuracy)\n",
    "loss, accuracy = test(selected_model, x_te, y_te)\n",
    "# get the prediction, precision, recall, and f1 score\n",
    "prediction, precision, recall, f1 = predict(selected_model, x_te, y_te)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABj8AAAKOCAYAAAD54wtlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSl0lEQVR4nOzde3yP9f/H8ednZ6dt5rAZM+dTYXKOnFotSqSSEkJ8UxORyrccEyXhS0r5OaTyrW8HIn2VQ5KcSd8SE8aEDTnMxo6f6/fH+nzq0zZttl2fg8f9drtuN9d1va/r9b4+W/q8vK/X+20xDMMQAAAAAAAAAACAh/BydgcAAAAAAAAAAACKE4MfAAAAAAAAAADAozD4AQAAAAAAAAAAPAqDHwAAAAAAAAAAwKMw+AEAAAAAAAAAADwKgx8AAAAAAAAAAMCjMPgBAAAAAAAAAAA8CoMfAAAAAAAAAADAozD4AQAAAAAAAAAAPIqPszsAAAAA5CUtLU0ZGRmmx/Xz81NAQIDpcQEAAACgMJyVM0nukTcx+AEAAACXk5aWppqRZZV4Otv02GFhYYqPjy/wF/lNmzbp1Vdf1e7du3Xq1CktX75cPXv2tJ9PSUnRc889pxUrVui3335TzZo19eSTT+qxxx6zt0lLS9Po0aP1wQcfKD09XTExMXrjjTcUGhpa3I8HAAAAwAM4M2eSCp83OQODHwAAAHA5GRkZSjydrWO7ayiwnHkztSZfsiqy+VFlZGQU+Et8amqqmjZtqkGDBqlXr165zo8aNUobNmzQe++9pxo1auirr77S448/rvDwcN19992SpKeeekqrV6/WRx99pKCgIMXGxqpXr1767rvvivX5AAAAAHgGZ+VM0rXlTc7A4AcAAABcVtlyFpUtZzEtnlWFj9W1a1d17do13/NbtmzRgAED1KlTJ0nS0KFD9dZbb2nHjh26++67dfHiRS1cuFDLli1Tly5dJEmLFy9Ww4YNtW3bNrVp0+aangUAAACA5zM7Z5KuLW9yBhY8BwAAAP4iOTnZYUtPT7/me918881auXKlTpw4IcMw9PXXX+vgwYO6/fbbJUm7d+9WZmamoqOj7dc0aNBA1atX19atW4v8LAAAAABwPWLwA4BpkpOTNWLECNWsWVO+vr6yWCzau3dvicasUaOGatSoUaIxPNnEiRNlsVi0cePGEotx+fJlVa1aVUOHDi2xGK4kMzNTtWrVUu/evZ3dFQBXERERoaCgIPs2bdq0a77X3Llz1ahRI1WrVk1+fn664447NG/ePHXo0EGSlJiYKD8/PwUHBztcFxoaqsTExKI8BgDAA5BHuZ/rJY86evSoLBaLHnnkkSLd5+GHH1ZkZKTS0tKKp2MA8DsGPwAPtnv3bg0ePFh169ZVmTJlVKpUKdWuXVv9+vXT2rVrTe/PM888ozlz5ujGG2/Uc889pwkTJigsLMz0fjhTjRo1ZLFYZLFY9NNPP+XZJjs7W1WrVrW3O3r06DXHW7JkiSwWi5YsWXLN9yhpr776qs6ePasXXnjB2V0pNo888ki+PztfX189//zz+uijj7Rt2zbzOwe4mWzDavomScePH9fFixft29ixY6/5GebOnatt27Zp5cqV2r17t1577TU98cQTWrduXXF9TACAYkQe5XrIo3IzK48yYyBs/PjxOnHihGbPnl2icQBP5YycyZY3uTrW/AA8kNVq1dNPP61Zs2bJx8dHXbp00d133y1fX18dOXJEq1ev1nvvvafJkydr3LhxpvXr888/V7169bRq1SrTYq5fv960WAXl5ZUz7rxo0SLNnDkz1/n//ve/OnnypHx8fJSVlWV29xzExsaqT58+ql69eoncPzk5WTNmzNADDzxQYjFc0YABA/TPf/5T48aNc0oCDeDvBQYGKjAwsMj3uXLliv75z39q+fLluvPOOyVJTZo00d69ezVjxgxFR0crLCxMGRkZunDhgkP1R1JS0nX3j1sA4EzkUX8gjyqa6yWPqlq1qvbv36+goKAi3adevXrq0aOHXn75ZQ0fPlxlypQpph4CuN4x+AF4oBdeeEGzZs1SVFSUPv74Y9WuXdvh/JUrV/T666/rt99+M7VfJ0+etE/xYZa/Prsr8PX1VYcOHfTee+/plVdeka+vr8P5RYsWKSgoSE2bNtWmTZuc1MscFStWVMWKFUvs/u+++65SUlLUv3//Eovhinx8fNSnTx/NnTtXhw4dUp06dZzdJcBlWWXIKsPUeMUpMzNTmZmZ9n+wsfH29pbVmvO2VPPmzeXr66v169fr3nvvlSTFxcUpISFBbdu2Ldb+AADyRx71B/Koorle8ihfX181aNCgWO718MMP69NPP9UHH3ygwYMHF8s9geuF2TmTLaY7YNorwMMcOnRI06dPV4UKFbRmzZo8v7SWKlVKY8aM0aRJkxyOnz17ViNHjlTNmjXl7++vypUrq3fv3nmWFdum9YmPj9ecOXPUoEED+fv7KzIyUpMmTbL/g86f2xqGoW+++cZehtypUydJV58PNb9y46+//lpdu3ZVeHi4/P39FRoaqltuuUVvv/22Q7v8SnRTU1M1YcIENWjQQAEBAQoJCdGdd96p7777LlfbP/dv2bJlioqKUqlSpVSlShWNGDFCV65cyXXN3xk0aJDOnDmT6+2tM2fO6PPPP9eDDz6oUqVK5bouIyNDc+fOVUxMjCIiIuw/p169eun77793aPvII49o4MCBkqSBAwfaP3eLxWJv06lTJ1ksFqWlpemFF15Q7dq15evrq4kTJ+Z6dpvHHntMFotFL7/8cq7+2c698sorBfocFi9erJCQEHXp0iXP86dPn9bo0aNVv359lSpVSiEhIWrdurVmzJiRq+2qVavUuXNnBQUFqVSpUmratKlmzpyZ662vjRs3ymKx2J/xz/Kbs9b2e5SSkqIRI0bYf++aNGmijz/+OFfbd955R5JUs2bNXL/vNr1795ZhGPa2ANxXSkqK9u7da59/PT4+Xnv37lVCQoICAwPVsWNHjRkzRhs3blR8fLyWLFmipUuX6p577pEkBQUFafDgwRo1apS+/vpr7d69WwMHDlTbtm3Vpk0bJz4ZAFw/yKPIo2zcPY+y/ewuXLig2NhYRUREyMfHx/67sHv3bsXGxurGG2+0506NGzfWyy+/rMzMTPt9bLnRsWPHdOzYMYfPwfacV1vz49ixYxo8eLCqVq0qPz8/VatWTYMHD1ZCQkKez3TnnXeqdOnSLj3VGAD3Q+UH4GGWLFmi7Oxs/eMf/1BoaOhV2/r7+9v/fObMGbVt21aHDx9Wp06d1KdPH8XHx+vjjz/W6tWr9eWXX6p9+/a57jFmzBh98803uuuuuxQTE6MVK1Zo4sSJysjI0EsvvSRJ6tmzp2rUqKFJkyYpMjLS/sXoWucNXb16tbp3767g4GD16NFDVapU0ZkzZ/TDDz/o3Xff/dsF39LS0tSlSxft2LFDN910k0aOHKmkpCR9+OGH+vLLL/Xvf/9b999/f67rXn/9da1Zs0Y9evRQly5dtGbNGs2ZM0dnz57V+++/X6hnuOeee1S+fHktXrxYvXr1sh9/9913lZmZqUGDBuVZSn/u3DmNHDlSt9xyi7p166by5cvryJEjWrlypf773/9q06ZNatmypaScz/3ChQv67LPP1KNHD0VFReXbn3vvvVc//PCD7rjjDgUHB6tmzZr5tp01a5Y2bdqk8ePH69Zbb7XHW758ud566y116dJFY8aM+dvP4Pz58/r+++91++2353ojWsp567lz5846deqU2rdvr549eyo1NVX79u3T1KlT9fTTT9vbzpw5U6NHj1ZISIgeeughlSlTRitXrtTo0aP17bff6tNPP3VIVq5FZmambr/9dp0/f1733nuvLl++rA8++EC9e/fWmjVrdPvtt0uSRo4cqSVLluiHH37QiBEj7FPY/PX3/c9ver/44otF6hsA59q1a5c6d+5s3x81apSknCnulixZog8++EBjx45V3759de7cOUVGRuqll17SY489Zr9m1qxZ8vLy0r333qv09HTFxMTojTfeMP1ZAOB6RR5FHuUpeZQkpaenq0uXLkpJSdHdd98tHx8f++/1ggULtGrVKnXo0EHdunXT5cuXtXHjRo0dO1Y7d+7UJ598IkkKDg7WhAkT7OtwjBw50n7/v77Y9VcHDx5U+/btdebMGXXv3l033HCDfvrpJy1atEirVq3S5s2bVa9ePYdr/Pz81Lx5c23dulWpqalMfQWgeBgAPEqnTp0MSca6desKdd3AgQMNScbYsWMdjq9evdqQZNSpU8fIzs62Hx8wYIAhyahZs6Zx8uRJ+/EzZ84YwcHBRrly5Yz09HSHe0kyOnbsmCv2hAkTDEnG119/nevc4sWLDUnG4sWL7cd69eplSDL27t2bq/3Zs2cd9iMjI43IyEiHY5MmTTIkGX379jWsVqv9+J49eww/Pz8jODjYSE5OztW/oKAg48CBA/bjly9fNurVq2d4eXkZJ06cyNWXvERGRhr+/v6GYRhGbGys4ePjY5w6dcp+/oYbbjAaN25sGIZhxMTEGJKM+Ph4+/m0tDTj119/zXXfn376yShbtqwRHR3tcDyvz+/POnbsaEgyoqKijN9++y3X+fx+Nnv37jX8/f2N2rVrG5cuXTKOHz9uhISEGBUqVCjwZ2H73Xr++efzPN+iRQtDkvH222/nOnf8+HH7nw8dOmT4+PgYlStXNhISEuzH09LSjPbt2xuSjKVLl9qPf/3114YkY8KECbnuGx8fb0gyBgwY4HA8MjLSkGT06NHD4fd63bp1hiQjJibGob3tv48//+zy0qxZM8PX19dIS0u7ajvgenTx4kVDknEyrpqRcrK6advJuGqGJOPixYvO/ggAACYijyKP+jN3zqNsuUtMTIxx+fLlXOePHTtmZGVlORyzWq3GoEGDDEnG5s2bc93vr78LNvnlT507dzYkGW+99ZbD8Xnz5hmSjC5duuR5v6eeesqQZGzYsCHP8wAcOStncqe8iWmvAA+TmJgoSapWrVqBr8nIyNC///1vVahQQS+88ILDuW7duum2227ToUOH8ixlHjdunKpUqWLfr1ixonr06KFLly4pLi7uGp+iYPIqZ65QocLfXvfOO+/I19dXL7/8skM1QLNmzTRgwABduHBBK1asyHXdiBEjVL9+fYf4Dz74oKxWq3bv3l3o/g8aNEhZWVn2aY+2b9+uffv2adCgQfle4+/vr6pVq+Y6fsMNN6hz587atGmTQ6lyQU2aNEkhISEFbt+0aVO98sorOnz4sIYNG6Z+/frp3LlzWrRokcLDwwt0j19//VWS8nyzbseOHdq1a5c6dOigIUOG5Dr/59/vZcuWKSsrS6NHj1ZERIT9uL+/v71svLhKp2fNmiU/Pz/7/q233qrIyEjt3Lnzmu4XGhqqzMxMnT59ulj6BwAAgGtDHkUe5Ql51J9Nnz49z5919erV5e3t7XDMYrHoiSeekCStW7euQP3IT0JCgr7++ms1atQoVy732GOPqUGDBtqwYYOOHz+e61rbM9meEQCKisEPADpw4IDS0tLUqlUrlS5dOtd521QetrnM/6x58+a5jtkShgsXLhRrP2369OkjSWrTpo1iY2O1fPlynT17tkDXJicn68iRI6pTp06eiY2Zz9qsWTNFRUVp8eLFknIW6PPz89PDDz981ev27t2rhx56SNWrV5efn5993tVVq1YpIyOjwJ/Fn7Vq1arQ1zz55JPq2rWr3nvvPW3cuFHDhg3T3XffXeDrbQtF2qaF+rMdO3ZIkn0qqauxzdGbV+l127ZtFRAQkOfPs7DyK2OvVq3aNf+u2xKla/mZAdeLbMMwfQMAoCDIo/5AHlVwJZlH2QQEBKhx48Z5nsvIyNDMmTPVqlUrBQYGysvLSxaLxf5zOnnyZMEfJg+234GOHTvmmnrYy8tLHTp0cGj3Z+RHwLVxRs7kLnkTgx+AhwkLC5MknThxosDXJCcnS8r/zRHbG0m2dn8WGBiY65iPT85yQtnZ2QXuQ2Hcf//9WrFihRo3bqz58+erV69eqly5sm699da//UduV3vWQYMGKS4uTuvWrdMHH3yg7t27q2LFivm237Jli9q0aaNPP/1UUVFRGj58uMaPH68JEyaoadOmknLmdy2sv3trKC8Wi0U9e/a07w8fPrxQ19veQkpLS8t17uLFi5KU59tZf3W1n6nFYlFoaGieP8/CCgoKyvO4j4+Pw8KUhWFb5DGvZBkAAADmIY/ae9VrXe1ZyaPyzqNsKleunO+ah/fdd59Gjx6tixcv6oEHHtDYsWM1YcIEjRgxQtK1fQ5/VpTfFfIjAMWNBc8BD9OuXTtt3LhR69evV5cuXQp0je3LaFJSUp7nbSXgeX1pLQ62RdqysrJynbP9I/hf9ejRw14W/t133+nTTz/VwoULdccdd+jAgQP5vgXj7Gf9q759+2rMmDF65JFHlJycrMGDB1+1/UsvvaT09HR9++23uRZO3LZtm3744Ydr6se1LAYeHx+vMWPGKCQkROfPn9ejjz6qTZs25Sqhzk+lSpUk5Sw++Fe2n19Bks8//0wjIyMdzhmGoaSkJIef57X8vpUU27PbPgsAuVllyCrz3ioyMxYAwHWQR5FHXQtXy6P+rl87d+7UqlWrFBMTo9WrVzvE3LZtm/71r38V4knyVpTfFfIj4NqYnTPZYroDKj8AD/PII4/I29tbb7/9ts6cOXPVtrY3Oho0aKCAgADt3LlTly9fztVu48aNkqSoqKji7q4kqXz58pLy/odu25RG+SlXrpzuuOMOvf3223rkkUeUlJSk7du359s+MDBQtWrV0qFDh/KMV9LP+lchISHq2bOnTpw4oapVqyomJuaq7Q8fPqyQkJBcX9gvX76sPXv25Gpv+zJb3G+PZWVlqW/fvrp06ZI+/PBDjRo1Slu2bNGkSZMKfA9bGXZecxrbyse/+uqrv71Ps2bNJP3xs/uz7du3Ky0tzeHnWZTft4Iq6OceFxenqlWrFmqeYAAAABQ/8ijyqD9z1zzq7xw+fFiSdOedd+YabPn222/zvMbb27tQn4Ptd2DTpk0y/jItjmEY2rRpk0O7P7M9U35TdgFAYTH4AXiYOnXq6JlnntHZs2fVtWtXxcfH52qTlpammTNnauLEiZIkPz8/Pfjggzp79qymTZvm0HbNmjX68ssvVadOHbVr165E+tyyZUtJ0tKlSx2mD9q6davef//9XO03bdqU55cv26LRAQEBV403YMAAZWZmauzYsQ5fxv73v/9pyZIlCgoKcihDLmkvv/yyli9frhUrVtjf3spPZGSkzp8/r3379tmPZWdn6+mnn84zSbP9o3pei8kVxaRJk7R161aNHj1a0dHRmjp1qm666SZNnTo13y/Nf9W4cWOFhITkmWS1bNlSLVu21KZNm7RgwYJc5/+ccD300EPy8fHRzJkzHeanzcjI0LPPPispJ5m1qV+/vsqVK6eVK1c6vC2VlJSkKVOmFKjvf6cgn3tCQoISExPtc94CAADAecijyKP+zF3zqL9jq5TfvHmzw/F9+/bl+h22CQkJ0dmzZ686zdafVa9eXZ07d9a+ffu0aNEih3Nvv/229u/fry5duigiIiLXtdu3b1eVKlVUt27dAsUCgL/DtFeAB5oyZYrS0tI0a9Ys1a9fX126dNGNN94oX19fxcfHa926dfrtt98c/qH3lVde0TfffKMpU6Zoy5Ytat26tY4ePaqPPvpIpUuX1uLFi//2C+W1atOmjdq1a6cNGzaobdu26tChg44dO6bPPvtM3bt31/Llyx3aP/nkkzp58qTat2+vGjVqyGKxaPPmzdqxY4fatGmT622ev3rmmWe0evVqvfvuu9q/f79uvfVWnT59Wh9++KGysrK0YMEClStXrkSeNS81atRQjRo1CtR2+PDh+uqrr9S+fXv17t1bAQEB2rhxo06cOKFOnTrlqn5o27atSpUqpdmzZ+v8+fP28uEXXnjhmvu7adMm+5f0l156SVJO4rds2TI1b95cDz/8sH744YerLsAn5ZRi9+jRQ0uWLNGvv/6aa+HE999/X506ddLQoUP17rvvqm3btkpLS9O+ffv0/fff2xf6q127tl555RWNHj1aTZo0Ue/evVWmTBmtWrVKcXFx6tGjh8Pih35+fho+fLj9GWxl/6tWrVLHjh3tb0MVRZcuXTRjxgwNHTpU9957r8qUKaPIyEj169fP3mbt2rWSZGqCCLgjqwxlM+0VAMAE5FHkUTbunEddTatWrdSqVSv95z//0alTp9SmTRslJCRo5cqVuvPOO/Xxxx/nuqZLly7atWuXunbtqltuuUV+fn7q0KHDVV/ievPNN9W+fXsNGTJEq1atUqNGjbRv3z6tXLlSlSpV0ptvvpnrmsOHDys+Pl7Dhg0r8PMAyGF2zmSL6Q6o/AA8kJeXl2bOnKmdO3eqX79+Onz4sN544w3NmjVL27dvV0xMjNauXavnn3/efk2lSpW0fft2Pfnkkzp8+LBmzJihtWvXqmfPntq+ffvffhEuqs8++0z9+/fXoUOHNG/ePB0/flyrVq3S3Xffnavt2LFj1blzZ/3vf//TW2+9pYULFyo9PV2vvPKK1q5d+7dzpQYEBGjDhg0aN26ckpOTNWvWLC1fvlwdO3bUxo0bdf/995fUYxbZXXfdpY8//li1atXSe++9p2XLlqlBgwbasWNHrvUupJy3dD7++GPVq1dPCxYs0Lhx4zRu3Lhrjn/+/Hk9/PDDKlWqlP7973/Lz8/Pfq5+/fqaPXu2EhISNGTIkALd77HHHpNhGFq2bFmuc3Xr1tWePXs0YsQInThxQrNnz9Z7772nlJSUXEnHqFGj9Nlnn+nGG2/Ue++9p7lz58rPz0+vvfaaPv7441xz3r744ouaOHGirFar5s+fr++++07jxo3Tq6++eg2fSm5du3bV9OnTJUmvvfaaxo0bp4ULFzq0ee+991S5cmXdc889xRITAAAARUMeRR5l48551NV4e3vr888/16BBg3T48GHNnTtXP//8s2bMmGHPX/5q3LhxGjJkiOLi4jR16lSNGzdOGzZsuGqc+vXra9euXXrkkUe0Y8cOvfrqq9q5c6cGDhyonTt3ql69ermuee+99yRJ//jHPwr1TABwNRbjrxPwAQBgoltuuUVnzpzRzz//XGJvxbmaX375RfXr19fEiRM1fvx4Z3cHcEnJyckKCgrS4QNhKlfOvL8bLl2yqnaDRF28eNG0RVsBAAAKy5PyqKysLNWtW1c1a9b824EVAH9wVs4kuU/e5N5/OwIA3N6rr76quLg4ffDBB87uimkmT56sKlWqaPTo0c7uCgAAAAA35El51DvvvKNjx45pxowZzu4KAA/D4AcAwKnatGmjt956K8/FFz1RZmam6tevr6VLl6pMmTLO7g4AAAAAN+RJeZTFYtGCBQt00003ObsrADwM014BAADA5dhKuA/uDzV92qt6DZNcvnwbAAAAwPXNWTmT5D55E5UfAAAAAAAAAADAo/g4uwMAAABAfqy/b2bGAwAAAAB3YXbOZIvpDhj8KCZWq1UnT55UuXLlZLFYnN0dAACAQjEMQ5cuXVJ4eLi8vCgOBlD8yJkAAIC7I29yLwx+FJOTJ08qIiLC2d0AAAAokuPHj6tatWrO7oZdtgxly7wl6syMBVxvyJkAAICncKW8yeycyRbTHTD4UUzKlSsnSTq2p4YCyzLqB6Bk3N8h2tldAOChsqwZ2nh6if07DQAUN9vfL5u2V1RZciYAJWRMhzud3QUAHizLmqFvzr9P3uQmGPwoJray7cCyXgosxxd5ACXDx8vP2V0A4OGYigZASbH9/VK2rJfKkjMBKCHkTADMQN7kHhj8AAAAgMvKNnI2M+MBAAAAgLswO2eyxXQHvG4DAAAAAAAAAAA8CpUfAAAAcFnW3zcz4wEAAACAuzA7Z7LFdAdUfgAAAAAAAAAAAI/C4AcAAAAAAAAAAPAoTHsFAAAAl2WVRdmymBoPAAAAANyF2TmTLaY7oPIDAAAAAAAAAAB4FCo/AAAA4LKsRs5mZjwAAAAAcBdm50y2mO6Ayg8AAAAAAAAAAOBRqPwAAACAy8o2ef5as+fKBQAAAICiMDtnssV0B1R+AAAAAAAAAAAAj8LgBwAAAAAAAAAA8ChMewUAAACXxbRXAAAAAJA/pr3KH5UfAAAAAAAAAADAo1D5AQAAAJdlNSyyGua9VWRmLAAAAAAoKrNzJltMd0DlBwAAAAAAAAAA8CgMfgAAAAAAAAAAAI/CtFcAAABwWSx4DgAAAAD5Y8Hz/FH5AQAAAAAAAAAAPAqVHwAAAHBZ2fJStonv62SbFgkAAAAAis7snCknpnug8gMAAAAAAAAAAHgUKj8AAADgsgzDIqth3nyyhomxAAAAAKCozM6ZbDHdAZUfAAAAAAAAAADAozD4AQAAAAAAAAAAPArTXgEAAMBlZcuibJlXUm1mLAAAAAAoKrNzJltMd0DlBwAAAAAAAAAA8ChUfgAAAMBlZRteyjbMe18n2zAtFAAAAAAUmdk5U05MU8NdMyo/AAAAAAAAAACAR2HwAwAAAAAAAAAAeBSmvQIAAIDLssoiq4nv61jlJvXbAAAAACDzc6acmO6RN1H5AQAAAAAAAAAAPAqVHwAAAHBZ2bIoWxZT4wEAAACAuzA7Z7LFdAdUfgAAAAAAAAAAAI9C5QcAAABcVrbhpWzDvPd1sg33mLsWAAAAACTzc6acmO6RN1H5AQAAAAAAAAAAPAqDHwAAAAAAAAAAwKMw7RUAAABcllUWWU1cTM/MWAAAAABQVGbnTLaY7oDKDwAAAAAAAAAA4FGo/AAAAIDLsspL2Sa+r2OVeyzcBwAAAACS+TlTTkz3yJuo/AAAAAAAAAAAAB6FwQ8AAAAAAAAAAOBRmPYKAAAALivb8FK2Yd77OtmGe5RvAwAAAIBkfs6UE9M98iYqPwAAAAAAAAAAgEeh8gMAAAAuyyovWVnwHAAAAADyZHbOlBPTPfImKj8AAAAAAAAAAECJmTdvnmrUqKGAgAC1bt1aO3bsuGr72bNnq379+ipVqpQiIiL01FNPKS0trVAxqfwAAACAy8o2LMo2LKbGAwAAAAB3YXbOZItZGB9++KFGjRql+fPnq3Xr1po9e7ZiYmIUFxenypUr52q/bNkyPffcc1q0aJFuvvlmHTx4UI888ogsFotmzpxZ4LhUfgAAAAAAAAAAgEJJTk522NLT0/NsN3PmTA0ZMkQDBw5Uo0aNNH/+fJUuXVqLFi3Ks/2WLVvUrl07PfTQQ6pRo4Zuv/12Pfjgg39bLfJXDH4AAAAARbBp0yZ1795d4eHhslgsWrFiRa42+/fv1913362goCCVKVNGLVu2VEJCgv18WlqannjiCVWoUEFly5bVvffeq6SkJBOfAgAAAAAKJyIiQkFBQfZt2rRpudpkZGRo9+7dio6Oth/z8vJSdHS0tm7dmud9b775Zu3evds+2HHkyBF98cUX6tatW6H6x7RXAAAAcFnZ8lK2ie/rZF/Dwn2pqalq2rSpBg0apF69euU6f/jwYbVv316DBw/WpEmTFBgYqH379ikgIMDe5qmnntLq1av10UcfKSgoSLGxserVq5e+++67Ij0PAAAAAM9mds6UEzMnbzp+/LgCAwPtx/39/XO1PXv2rLKzsxUaGupwPDQ0VAcOHMjz/g899JDOnj2r9u3byzAMZWVl6bHHHtM///nPQvWTwQ8AAACgCLp27aquXbvme/75559Xt27dNH36dPux2rVr2/988eJFLVy4UMuWLVOXLl0kSYsXL1bDhg21bds2tWnTpuQ6DwAAAADXKDAw0GHwo7hs3LhRU6dO1RtvvKHWrVvr0KFDGjFihF588UWNGzeuwPdh2isAAAC4LKvhZfomFXzu2r/tv9Wq1atXq169eoqJiVHlypXVunVrh6mxdu/erczMTIcy8AYNGqh69er5loEDAAAAgOScnMmWNxVExYoV5e3tnWta36SkJIWFheV5zbhx49SvXz89+uijaty4se655x5NnTpV06ZNk9VqLXBsBj8AAACAvyjI3LUFcfr0aaWkpOjll1/WHXfcoa+++kr33HOPevXqpW+++UaSlJiYKD8/PwUHBztcGxoaqsTExKI+CgAAAAA4jZ+fn5o3b67169fbj1mtVq1fv15t27bN85rLly/Ly8tx6MLb21uSZBgFn6qYaa8AAACAvyjI3LUFYXsrqUePHnrqqackSVFRUdqyZYvmz5+vjh07Fr2zAAAAAODCRo0apQEDBqhFixZq1aqVZs+erdTUVA0cOFCS1L9/f1WtWtX+0ln37t01c+ZMNWvWzD7t1bhx49S9e3f7IEhBMPgBAAAAl+WsBc+La+7aihUrysfHR40aNXI43rBhQ23evFmSFBYWpoyMDF24cMGh+uNqZeAAAAAAIDl3wfOCeuCBB3TmzBmNHz9eiYmJioqK0po1a+yLoCckJDhUerzwwguyWCx64YUXdOLECVWqVEndu3fXSy+9VKi4DH4AAAAAJcTPz08tW7ZUXFycw/GDBw8qMjJSktS8eXP5+vpq/fr1uvfeeyVJcXFxSkhIyLcMHAAAAADcSWxsrGJjY/M8t3HjRod9Hx8fTZgwQRMmTChSTAY/AAAA4LKskrINi6nxCislJUWHDh2y78fHx2vv3r0KCQlR9erVNWbMGD3wwAPq0KGDOnfurDVr1mjVqlX2L/hBQUEaPHiwRo0apZCQEAUGBmr48OFq27at2rRpUzwPBgAAAMAjmZ0z2WK6AwY/AAAAgCLYtWuXOnfubN8fNWqUJGnAgAFasmSJ7rnnHs2fP1/Tpk3Tk08+qfr16+uTTz5R+/bt7dfMmjVLXl5euvfee5Wenq6YmBi98cYbpj8LAAAAAHgKBj8AAACAIujUqZMM4+pz3g4aNEiDBg3K93xAQIDmzZunefPmFXf3AAAAAOC6xOAHAAAAXJZVXrKauHifmbEAAAAAoKjMzplsMd2Be/QSAAAAAAAAAACggKj8AAAAgMvKNryUbZj3vo6ZsQAAAACgqMzOmWwx3YF79BIAAAAAAAAAAKCAqPwAAACAy7LKIqsspsYDAAAAAHdhds5ki+kOqPwAAAAAAAAAAAAehcEPAAAAAAAAAADgUZj2CgAAAC6LBc8BAAAAIH8seJ4/9+glAAAAAAAAAABAAVH5AQAAAJeVLS9lm/i+jpmxAAAAAKCozM6ZbDHdgXv0EgAAAAAAAAAAoIAY/AAAAAAAAAAAAB6Faa8AAADgsqyGRVbDYmo8AAAAAHAXZudMtpjugMoPAAAAAAAAAADgUaj8AAAAgMuymrx4n5V3gwAAAAC4EbNzJltMd+AevQQAAAAAAAAAACggKj8AAADgsqyGl6yGiZUfJsYCAAAAgKIyO2eyxXQH7tFLAAAAAAAAAACAAmLwAwAAAAAAAAAAeBSmvQIAAIDLypZF2bKYGg8AAAAA3IXZOZMtpjug8gMAAAAAAAAAAHgUKj8AAADgsljwHAAAAADyx4Ln+XOPXgIAAAAAAAAAABQQgx8AAAAAAAAAAMCjMO0VAAAAXFa2zF1ML9u0SAAAAABQdGbnTLaY7oDKDwAAAAAAAAAA4FGo/AAAAIDLYsFzAAAAAMgfC57nzz16CQAAAAAAAAAAUEBUfgAAAMBlZRteyjbxrSIzYwEAAABAUZmdM9liugP36CUAAAAAAAAAAEABMfgBAAAAAAAAAAA8CtNeAQAAwGUZssgqi6nxAAAAAMBdmJ0z2WK6Ayo/AAAAAAAAAACAR6HyAwAAAC6LBc8BAAAAIH8seJ4/9+glAAAAAAAAAABAATH4AQAAAAAAAAAAPArTXgEAAMBlWQ2LrIZ5i+mZGQsAAAAAisrsnMkW0x1Q+QEAAAAAAAAAADwKlR8AAABwWdnyUraJ7+uYGQsAAAAAisrsnMkW0x24Ry8BAAAAAAAAAAAKiMoPAAAAuCzW/AAAAACA/LHmR/6o/AAAAAAAAAAAAB6FwQ8AAAAAAAAAAOBRmPYKAAAALssqL1lNfF/HzFgAAAAAUFRm50y2mO7APXoJAAAAAAAAAABQQFR+AAAAwGVlGxZlm7iYnpmxAAAAAKCozM6ZbDHdAZUfAAAAAAAAAADAozD4AQAAAAAAAAAAPArTXgEAAMBlWQ2LrCaWVJsZCwAAAACKyuycyRbTHVD5AQAAAAAAAAAAPAqVHwAAAHBZhuElq2He+zqGibEAAAAAoKjMzplsMd2Be/QSAAAAAAAAAACggKj8AAAAgMvKlkXZMm8+WTNjAQAAAEBRmZ0z2WK6Ayo/AAAAAAAAAACAR2HwAwAAAAAAAAAAeBSmvQIAAIDLshqS1TCvpNpqmBYKAAAAAIrM7JzJFtMdUPkBAAAAAAAAAAA8CpUfAAAAcFlWw0tWw7z3dcyMBQAAAABFZXbOZIvpDtyjlwAAAAAAAAAAAAXE4AcAAAAAAAAAAPAoTHsFAAAAl2WVRVaZuOC5ibEAAAAAoKjMzplsMd0BlR8AAAAAAAAAAMCjUPkBAAAAl5VtWJRtmPdWkZmxAAAAAKCozM6ZbDHdAZUfAAAAAAAAAACgxMybN081atRQQECAWrdurR07duTbtlOnTrJYLLm2O++8s1AxqfwAAACAy7IaXrIa5r2vY2YsAAAAACgqs3MmW8zC+PDDDzVq1CjNnz9frVu31uzZsxUTE6O4uDhVrlw5V/tPP/1UGRkZ9v3ffvtNTZs21f3331+ouGR3AAAAQBFs2rRJ3bt3V3h4uCwWi1asWJFv28cee0wWi0WzZ892OH7u3Dn17dtXgYGBCg4O1uDBg5WSklKyHQcAAACAIkhOTnbY0tPT82w3c+ZMDRkyRAMHDlSjRo00f/58lS5dWosWLcqzfUhIiMLCwuzb2rVrVbp0aQY/AAAAADOlpqaqadOmmjdv3lXbLV++XNu2bVN4eHiuc3379tW+ffu0du1aff7559q0aZOGDh1aUl0GAAAAgCKLiIhQUFCQfZs2bVquNhkZGdq9e7eio6Ptx7y8vBQdHa2tW7cWKM7ChQvVp08flSlTplD9Y9orAAAAuCyrLLKauJieVYWP1bVrV3Xt2vWqbU6cOKHhw4fryy+/zDVP7f79+7VmzRrt3LlTLVq0kCTNnTtX3bp104wZM/IcLAEAAAAAyfycyRZTko4fP67AwED7cX9//1xtz549q+zsbIWGhjocDw0N1YEDB/421o4dO/TTTz9p4cKFhe4nlR8AAADAXxS0fLsgrFar+vXrpzFjxuiGG27IdX7r1q0KDg62D3xIUnR0tLy8vLR9+/ZrjgsAAAAAJSkwMNBhy2vwo6gWLlyoxo0bq1WrVoW+lsEPAAAAuCxDlpw3mUzajN/fYCpI+XZBvfLKK/Lx8dGTTz6Z5/nExMRci/z5+PgoJCREiYmJ1xwXAAAAgOczO2f6c95UEBUrVpS3t7eSkpIcjiclJSksLOyq16ampuqDDz7Q4MGDr+mzYdorAAAA4C8KUr5dELt379a//vUv7dmzRxaLuaXoAAAAAOBsfn5+at68udavX6+ePXtKyqmOX79+vWJjY6967UcffaT09HQ9/PDD1xSbyg8AAADgL4qrfPvbb7/V6dOnVb16dfn4+MjHx0fHjh3T6NGjVaNGDUlSWFiYTp8+7XBdVlaWzp0797dvQgEAAACAqxs1apQWLFigd955R/v379ewYcOUmpqqgQMHSpL69++vsWPH5rpu4cKF6tmzpypUqHBNcan8AAAAgMuyGiYveF7Msfr166fo6GiHYzExMerXr5/9i37btm114cIF7d69W82bN5ckbdiwQVarVa1bty7W/gAAAADwLGbnTLaYhfHAAw/ozJkzGj9+vBITExUVFaU1a9bYF0FPSEiQl5djnUZcXJw2b96sr7766pr7yeAHAAAAUAQpKSk6dOiQfT8+Pl579+5VSEiIqlevnustJV9fX4WFhal+/fqSpIYNG+qOO+7QkCFDNH/+fGVmZio2NlZ9+vRReHi4qc8CAAAAACUhNjY232muNm7cmOtY/fr1ZRhGkWIy+AEAAACXZTW8ZDXMm6n1WmLt2rVLnTt3tu+PGjVKkjRgwAAtWbKkQPd4//33FRsbq1tvvVVeXl669957NWfOnEL3BQAAAMD1xeycyRbTHTD4kQ+LxaLly5fbF2EBCuLHbWX00RuV9cuPpXUuyVcTFsbr5q4X7eevpHpp4UtVtPXLICWf91FYRIZ6DD6ju/r/Zm/zxXsV9PXy8jr0YyldTvHWJ/t/VNmgbGc8DgA30O2+BHW777hCq1yRJB07Ulb/XlBbu7dUkiTdcc9xdbzjlOo0SFbpstnq3bGLUlN8ndllwON06tSpUG8kHT16NNexkJAQLVu2rBh7BZQ8ciZci2/eqaK1b1dV8hk/VWuYqt6TDqtGVEq+7TcsDNem98J0/oS/yoRk6aZuZ9XjmaPyDcj5e/fzWdX1xezqDteE1r6sCRv2lOhzAHBNdz3wq+59JEHlK2Yo/mBZvTmtng7+FJhn2+q1U9TviXjVaXhJoVXT9Nb0uvrsvQiHNn2HHVHfYUcdjh2PL61/9GhTUo8AoBgx+AEUo7TLXqp1wxXFPHhOkwfXzHX+rYnh2vtdOT0zN0GhERna8005zR1bTRVCM9U2JjnnHle81KJTslp0StaiaUx1AeDqziYFaMncejqZUFqySNF3ndS4md/ryYduVsKRsvIPyNaerRW1Z2tFPTL8F2d3FwAAXMd2raqoT6bU1IMvHVKNqEvasKiq5va7URO/3q1yFTNztd+5opJWvFJD/ab/olrNk5UUX0rvjq4rSbpvfLy9XZV6qXry/Z/s+94+RZsiA4B76hCTpCFjftHrL9bXgR+D1PPh43px/l4NvbuNLp7zy9XeP8CqU7+W0rdfVdbQMfnnSkcPldHzQ6Ls+9nZ5q6tAODaMfgBFKOWXS6pZZdL+Z7/eVcZ3Xb/OTW9OefNpm4P/6bV71ZQ3N7S9sGPXkPOSJJ+2FK25DsMwO3t+Layw/7SN+qq230JatD4ghKOlNVn/64hSWrc/JwTegcUnbsveA4A+MOG/6uqdn0S1bb3aUnSg1MP6acN5bXlP6GKefzXXO2P7C6n2s2T1bJnTo5UISJdLe4+q6N7HXMlbx9DQZVzD54AuL7c0/+41nwSrrWf5bxI+vqL9dXylrO6vedJfbSoRq72v+wL1C/7cqpCBo44nO99s7MsOv+bf4n0GSgO7rDgubO4x+RcBfDxxx+rcePGKlWqlCpUqKDo6GilpqZq586duu2221SxYkUFBQWpY8eO2rPHsfz1l19+UYcOHRQQEKBGjRpp7dq1TnoKeLpGLVK17asgnT3lK8OQ9n5XVieO+Kt5x/wHTACgoLy8DHW4/ZQCSmVr//+Cnd0dAICLIWeCM2VlWJTwY1nVb3/BfszLS2rQ/oLi95TL85pazS8p4aey9sGOswn++unr8rqh83mHdqfjS2lsy5Ya176FFj9ZT+dO8I+UwPXGx8eqOg0vae+2EPsxw7Bo7/YQNWiaXKR7V428rHfXbdbCL7ZozLR9qhSWVtTuAjCJR1R+nDp1Sg8++KCmT5+ue+65R5cuXdK3334rwzB06dIlDRgwQHPnzpVhGHrttdfUrVs3/fLLLypXrpysVqt69eql0NBQbd++XRcvXtTIkSP/NmZ6errS09Pt+8nJRfuLFNeHx6ec0L+eiVDf5jfI28eQl5ehEa8eV+M2qc7uGgA3Flnnkl5bvF1+flZdueKtKU830/F4qsfgGayyyCoTKz9MjAWYiZwJzpZy3lfWbIsC/zK9VbmKmUo6XDrPa1r2PKOU8z567b4mMgzJmuWlWx4+pTti/6gSqRl1Sf1fO6jKta4o+bSfVs+urpn3N9YLX32vgLKsnQhcLwLLZ8rbx9D53xynt7rwm58ial6+5vvG/RikmS800q9HSyukUroeeixery7ZrWG9WuvKZY/4Z1V4ALNzJltMd+AR/5WeOnVKWVlZ6tWrlyIjIyVJjRs3liR16dLFoe3bb7+t4OBgffPNN7rrrru0bt06HThwQF9++aXCw3PK4qZOnaquXbteNea0adM0adKkEngaeLLPFlXUgd2lNWnJEVWulqEft5XVvH/mrPlxU4f8F/kDgKs5cbSMhj/YVmXKZqlddJJGTfpRzw5pxQAIAMCOnAnu6ODWIH05L0J9XjysGs0u6czRUvpoUk198a8IdRtxXJIcq0AaXlaNqEt6oV1L7f68otr1SXJSzwF4il2bK9j/fPSXsor7MVBL1mzRLTGn9dVy1mkFXJ1HTHvVtGlT3XrrrWrcuLHuv/9+LViwQOfP53wBSkpK0pAhQ1S3bl0FBQUpMDBQKSkpSkhIkCTt379fERER9i/xktS2bdu/jTl27FhdvHjRvh0/frxkHg4eI/2KRUterqKhE0+qze3JqtUoTT0GnVXHuy/o4/mV//4GAJCPrCwvnfq1jA4dCNI7r9dT/MFy6vHgMWd3CygWtvlrzdwAT0TOBGcrWz5TXt6Gks/6Ohy/dNZXgZUy8rxm1WvV1eqe02r3YJKqNrisqDt+091jjunLN6rJas07TumgbFWueUVnjgUU9yMAcGHJ532VnWVR+QqOf58EV8jQubO5Fzu/VqmXfHXiWGmFR1wptnsCReWMnMld8iaPGPzw9vbW2rVr9d///leNGjXS3LlzVb9+fcXHx2vAgAHau3ev/vWvf2nLli3au3evKlSooIyMvL9cFZS/v78CAwMdNuBqsrIsysr0kpeX4XDcy9uQkc8XdwC4FhYvydePv1gAAH8gZ4Kz+fgZqt44RXHfBduPWa1S3HfBqnlT3msgZlzxluUv/2rh5f17PmXkbi9JaaleOnssQEGVi/b7C8C9ZGV56dD+cmra+o9qMIvFUFTr8zrwQ/H9/yegVJaqRFwp1gEVACXHI6a9kiSLxaJ27dqpXbt2Gj9+vCIjI7V8+XJ99913euONN9StWzdJ0vHjx3X27Fn7dQ0bNtTx48d16tQpValSRZK0bds2pzwD3N+VVC+djP9jcb3E4346/FMplQvOUuVqmWrSNkULXgyXX8AJhVbL0P+2ltW6j0M0dMIJ+zXnTvvo/GlfnYzP+R9p/IEAlS5jVaWqGQosz5y1ABwNiD2oXd9V1JnEUipVJkud7jilxs3PaVxsc0lS+QrpKl8hXVUicua5rVEnRVcue+t0YoBSkvnCDgDXE3ImOFuXR09o6eh6imySosiml/T1onClX/ZW2/tzpqda8lQ9BYelq+ezORWsjaPPacP/hSvihhTViLqkM8dK6fPXItU4+py8vHPu+cmUGmocfU4VqqbrQpKfVs+qLi9vqcXdZ5z1mACcZPnSCI2asl+//FxOB38MVI+Hj8u/VLbWrsipXBz90s/6LclfS+bUlpSzSHr12jlrsPr4WlWhcrpq1b+kK5e9dep4zlpEg0f/ou0bK+r0qQBVqJShhx8/Imu2RRv/G+qchwRQKB4x+LF9+3atX79et99+uypXrqzt27frzJkzatiwoerWrat3331XLVq0UHJyssaMGaNSpUrZr42Ojla9evU0YMAAvfrqq0pOTtbzzz/vxKeBOzv4Q2k9c18d+/5bE6tKkm7rfU5Pz07Q2DePatHUKnoltrouXfBR5aoZeuTZU7qr/2/2a1Yvraj3ZobZ95++p64kafSsBN3+wDmTngSAuwgun6HRk39USMV0pab46ugvZTUutrn2bq8oSep673H1/cdhe/vpC3dIkmZNvFHrVlV1Sp+BwjC7pNpdyreBwiJngito0f2sUn7z1eczqyv5jJ+qNUpV7NKfFFgpZxH08yf9HSrluw5PkMViaNWMSF1I9FPZCplqfOs53T3mj+k9LyT6a/Hw+kq94KuyIZmq3TJZY1b8oHIVskx/PgDOtenLUAWWz1S/x4+ofMUMHYkrp/HDmurCuZyXviqFpTlMmRdSOV2vf7TTvn/fIwm675EE/W9nsJ4bfJMkqWLldD37yj4FBmfq4nk/7dsTpKcebq7k87xIBtfhjGmo3CVv8ojBj8DAQG3atEmzZ89WcnKyIiMj9dprr6lr164KCwvT0KFDddNNNykiIkJTp07V008/bb/Wy8tLy5cv1+DBg9WqVSvVqFFDc+bM0R133OHEJ4K7anpzir48uTff8yGVs/T07KvPddzv6UT1ezqxmHsGwFP968Ubr3p+2dt1tOztOldtAwDwfORMcBWdHjmlTo+cyvPcUx/+6LDv7SPdOfK47hyZfw41+PW4Yu0fAPf2+QfV9PkH1fI8ZxvQsDl9spS6Nely1fu98uzV8y0Ars0jBj8aNmyoNWvW5HmuWbNm2rlzp8Ox++67z2G/Xr16+vbbbx2OGUY+E4gCAADANFR+AMWDnAkAAMAzUfmRP49Y8BwAAAAAAAAAAMCGwQ8AAAAAAAAAAOBRPGLaKwAAAHgmpr0CAAAAgPwx7VX+qPwAAAAAAAAAAAAehcoPAAAAuCxDklXmvVXE8s0AAAAA3InZOZMtpjug8gMAAAAAAAAAAHgUKj8AAADgsljzAwAAAADyx5of+aPyAwAAAAAAAAAAeBQGPwAAAAAAAAAAgEdh2isAAAC4LKa9AgAAAID8Me1V/qj8AAAAAAAAAAAAHoXKDwAAALgsKj8AAAAAIH9UfuSPyg8AAAAAAAAAAOBRGPwAAAAAAAAAAAAehWmvAAAA4LKY9goAAAAA8se0V/mj8gMAAAAAAAAAAHgUKj8AAADgsgzDIsPEt4rMjAUAAAAARWV2zmSL6Q6o/AAAAAAAAAAAAB6Fyg8AAAC4LKssssrENT9MjAUAAAAARWV2zmSL6Q6o/AAAAAAAAAAAAB6FwQ8AAAAAAAAAAOBRmPYKAAAALstqWGQ1cTE9M2MBAAAAQFGZnTPZYroDKj8AAAAAAAAAAIBHofIDAAAALsswLDJMfKvIzFgAAAAAUFRm50y2mO6Ayg8AAAAAAAAAAOBRGPwAAAAAAAAAAAAehWmvAAAA4LJY8BwAAAAA8seC5/mj8gMAAAAAAAAAAHgUKj8AAADgsljwHAAAAADyx4Ln+aPyAwAAAAAAAAAAeBQqPwAAAOCyDJPnr3WXN5gAAAAAQDI/Z7LFdAdUfgAAAAAAAAAAAI/C4AcAAAAAAAAAAPAoTHsFAAAAl2VIMgxz4wEAAACAuzA7Z7LFdAdUfgAAAAAAAAAAAI9C5QcAAABcllUWWWTeYnpWE2MBAAAAQFGZnTPZYroDKj8AAAAAAAAAAIBHYfADAAAAAAAAAAB4FKa9AgAAgMsyDIsMw7ySajNjAQAAAEBRmZ0z2WK6Ayo/AAAAAAAAAACAR6HyAwAAAC7LalhkMfGtIqubvMEEAAAAAJL5OZMtpjug8gMAAAAAAAAAAHgUKj8AAADgsgwjZzMzHgAAAAC4C7NzJltMd0DlBwAAAAAAAAAA8CgMfgAAAAAAAAAAAI/CtFcAAABwWYZhkWHiYnpmxgIAAACAojI7Z7LFdAdUfgAAAAAAAAAAAI9C5QcAAABcFpUfAAAAAJA/Kj/yR+UHAAAAAAAAAADwKAx+AAAAAAAAAAAAj8K0VwAAAHBZVsMii4kl1VY3Kd8GAAAAAMn8nMkW0x1Q+QEAAAAAAAAAADwKlR8AAABwWYaRs5kZDwAAAADchdk5ky2mO6DyAwAAAAAAAAAAlJh58+apRo0aCggIUOvWrbVjx46rtr9w4YKeeOIJValSRf7+/qpXr56++OKLQsVk8AMAAAAuK+ctJouJW+H7uGnTJnXv3l3h4eGyWCxasWKF/VxmZqaeffZZNW7cWGXKlFF4eLj69++vkydPOtzj3Llz6tu3rwIDAxUcHKzBgwcrJSWliJ8eAAAAAE9nfs5U+Lzpww8/1KhRozRhwgTt2bNHTZs2VUxMjE6fPp1n+4yMDN122206evSoPv74Y8XFxWnBggWqWrVqoeIy+AEAAAAUQWpqqpo2bap58+blOnf58mXt2bNH48aN0549e/Tpp58qLi5Od999t0O7vn37at++fVq7dq0+//xzbdq0SUOHDjXrEQAAAACgxMycOVNDhgzRwIED1ahRI82fP1+lS5fWokWL8my/aNEinTt3TitWrFC7du1Uo0YNdezYUU2bNi1UXNb8AAAAAIqga9eu6tq1a57ngoKCtHbtWodjr7/+ulq1aqWEhARVr15d+/fv15o1a7Rz5061aNFCkjR37lx169ZNM2bMUHh4eIk/AwAAAAAUVnJyssO+v7+//P39HY5lZGRo9+7dGjt2rP2Yl5eXoqOjtXXr1jzvu3LlSrVt21ZPPPGEPvvsM1WqVEkPPfSQnn32WXl7exe4f1R+AAAAwGWZX75tkZTzJf7PW3p6erE908WLF2WxWBQcHCxJ2rp1q4KDg+0DH5IUHR0tLy8vbd++vdjiAgAAAPA8zsiZbHlTRESEgoKC7Nu0adNy9e/s2bPKzs5WaGiow/HQ0FAlJibm+UxHjhzRxx9/rOzsbH3xxRcaN26cXnvtNU2ZMqVQnw2VHwAAAMBfREREOOxPmDBBEydOLPJ909LS9Oyzz+rBBx9UYGCgJCkxMVGVK1d2aOfj46OQkJB8kwEAAAAAcLbjx4/b8xpJuao+rpXValXlypX19ttvy9vbW82bN9eJEyf06quvasKECQW+D4MfAAAAcFnG75uZ8aSS+RKfmZmp3r17yzAMvfnmm0W+HwAAAACYnTPZYkpSYGCgQ96Ul4oVK8rb21tJSUkOx5OSkhQWFpbnNVWqVJGvr6/DFFcNGzZUYmKiMjIy5OfnV6B+Mu0VAAAA8Be2L/G2raiDH7aBj2PHjmnt2rUOCUJYWJhOnz7t0D4rK0vnzp3LNxkAAAAAAHfg5+en5s2ba/369fZjVqtV69evV9u2bfO8pl27djp06JCsVqv92MGDB1WlSpUCD3xIDH4AAAAAJco28PHLL79o3bp1qlChgsP5tm3b6sKFC9q9e7f92IYNG2S1WtW6dWuzuwsAAAAAxWrUqFFasGCB3nnnHe3fv1/Dhg1TamqqBg4cKEnq37+/w4Low4YN07lz5zRixAgdPHhQq1ev1tSpU/XEE08UKi7TXgEAAMBl/XkxPbPiFVZKSooOHTpk34+Pj9fevXsVEhKiKlWq6L777tOePXv0+eefKzs7276OR0hIiPz8/NSwYUPdcccdGjJkiObPn6/MzEzFxsaqT58+Cg8PL7ZnAwAAAOB5zM6ZbDEL44EHHtCZM2c0fvx4JSYmKioqSmvWrLEvgp6QkCAvrz/qNCIiIvTll1/qqaeeUpMmTVS1alWNGDFCzz77bKHiMvgBAAAAFMGuXbvUuXNn+/6oUaMkSQMGDNDEiRO1cuVKSVJUVJTDdV9//bU6deokSXr//fcVGxurW2+9VV5eXrr33ns1Z84cU/oPAAAAACUtNjZWsbGxeZ7buHFjrmNt27bVtm3bihSTwQ8AAAC4LmeteF4InTp1kmHkf+HVztmEhIRo2bJlhQ8OAAAA4PrmzBXPXRxrfgAAAAAAAAAAAI/C4AcAAAAAAAAAAPAoTHsFAAAA12X24n0mLxQIAAAAAEXihAXP3SVvovIDAAAAAAAAAAB4FCo/AAAA4LIMI2czMx4AAAAAuAuzcyZbTHdA5QcAAAAAAAAAAPAoVH4AAADAZRkmz19r+ly5AAAAAFAEZudMtpjugMoPAAAAAAAAAADgURj8AAAAAAAAAAAAHoVprwAAAOC6DEvOZmY8AAAAAHAXZudMtphugMoPAAAAAAAAAADgUaj8AAAAgMsyjJzNzHgAAAAA4C7MzplsMd0BlR8AAAAAAAAAAMCjMPgBAAAAAAAAAAA8CtNeAQAAwHUZv29mxgMAAAAAd2F2zmSL6Qao/AAAAAAAAAAAAB6Fyg8AAAC4LMOwyDAspsYDAAAAAHdhds5ki+kOqPwAAAAAAAAAAAAehcoPAAAAuDY3mU8WAAAAAJyCnClPVH4AAAAAAAAAAACPwuAHAAAAAAAAAADwKEx7BQAAAJfFgucAAAAAkD8WPM8flR8AAAAAAAAAAMCjUPkBAAAA12XI3MX7WCgQAAAAgDsxO2eyxXQDVH4AAAAAAAAAAACPwuAHAAAAAAAAAADwKEx7BQAAABdm+X0zMx4AAAAAuAuzcyZbTNdH5QcAAAAAAAAAAPAoVH4AAADAdbHgOQAAAADkjwXP80XlBwAAAAAAAAAA8ChUfgAAAMB1UfkBAAAAAPmj8iNfVH4AAAAAAAAAAACPwuAHAAAAAAAAAADwKEx7BQAAANdlWHI2M+MBAAAAgLswO2eyxXQDVH4AAAAAAAAAAACPQuUHAAAAXJZh5GxmxgMAAAAAd2F2zmSL6Q6o/AAAAAAAAAAAAB6FwQ8AAAAAAAAAAOBRCjTt1cqVKwt8w7vvvvuaOwMAAAA4MH7fzIwHXANyJgAAADiF2TmTLaYbKNDgR8+ePQt0M4vFouzs7KL0BwAAAADcDjkTAAAA4FoKNPhhtVpLuh8AAABAboYlZzMzHnANyJkAAADgFGbnTLaYbqBIa36kpaUVVz8AAAAAwOOQMwEAAADOUejBj+zsbL344ouqWrWqypYtqyNHjkiSxo0bp4ULFxZ7BwEAAHD9shjmb0BRkTMBAADALM7Imdwlbyr04MdLL72kJUuWaPr06fLz87Mfv/HGG/V///d/xdo5AAAAAHA35EwAAACA8xV68GPp0qV6++231bdvX3l7e9uPN23aVAcOHCjWzgEAAACAuyFnAgAAAJyvQAue/9mJEydUp06dXMetVqsyMzOLpVMAAACAJMn4fTMzHlBE5EwAAAAwjdk5ky2mGyh05UejRo307bff5jr+8ccfq1mzZsXSKQAAAABwV+RMAAAAgPMVuvJj/PjxGjBggE6cOCGr1apPP/1UcXFxWrp0qT7//POS6CMAAACuV4YlZzMzHlBE5EwAAAAwjdk5ky2mGyh05UePHj20atUqrVu3TmXKlNH48eO1f/9+rVq1SrfddltJ9BEAAAAA3AY5EwAAAOB8ha78kKRbbrlFa9euLe6+AAAAAIBHIGcCAAAAnOuaBj8kadeuXdq/f7+knDltmzdvXmydAgAAACSx4DncGjkTAAAAShwLnuer0IMfv/76qx588EF99913Cg4OliRduHBBN998sz744ANVq1atuPsIAAAAAG6DnAkAAABwvkKv+fHoo48qMzNT+/fv17lz53Tu3Dnt379fVqtVjz76aEn0EQAAANcrwwkbUETkTAAAADCNM3ImN8mbCl358c0332jLli2qX7++/Vj9+vU1d+5c3XLLLcXaOQAAAABwN+RMAAAAgPMVevAjIiJCmZmZuY5nZ2crPDy8WDoFAAAASGLND7glciYAAACYhjU/8lXoaa9effVVDR8+XLt27bIf27Vrl0aMGKEZM2YUa+cAAAAAwN2QMwEAAADOV6DKj/Lly8tisdj3U1NT1bp1a/n45FyelZUlHx8fDRo0SD179iyRjgIAAACAqyJnAgAAAFxLgQY/Zs+eXcLdAAAAAPJgWHI2M+MB14CcCQAAAE5hds5ki+kGCjT4MWDAgJLuBwAAAAC4LXImAAAAwLUUesHzP0tLS1NGRobDscDAwCJ1CAAAALCxGDmbmfGA4kTOBAAAgJJkds5ki+kOCr3geWpqqmJjY1W5cmWVKVNG5cuXd9gAAAAA4HpGzgQAAAA4X6EHP5555hlt2LBBb775pvz9/fV///d/mjRpksLDw7V06dKS6CMAAAAAuA1yJgAAAMD5Cj3t1apVq7R06VJ16tRJAwcO1C233KI6deooMjJS77//vvr27VsS/QQAAMD1yPh9MzMeUETkTAAAADCN2TmTLaYbKHTlx7lz51SrVi1JOXPVnjt3TpLUvn17bdq0qXh7BwAAAABuhpwJAAAAcL5CD37UqlVL8fHxkqQGDRroP//5j6Sct5uCg4OLtXMAAAAA4G7ImQAAAADnK/Tgx8CBA/XDDz9Ikp577jnNmzdPAQEBeuqppzRmzJhi7yAAAADgyjZt2qTu3bsrPDxcFotFK1ascDhvGIbGjx+vKlWqqFSpUoqOjtYvv/zi0ObcuXPq27evAgMDFRwcrMGDByslJcXEp0BxImcCAAAAHM2bN081atRQQECAWrdurR07duTbdsmSJbJYLA5bQEBAoWMWes2Pp556yv7n6OhoHThwQLt371adOnXUpEmTQncAAAAAyI9FksXE+WQt13BNamqqmjZtqkGDBqlXr165zk+fPl1z5szRO++8o5o1a2rcuHGKiYnRzz//bP8C37dvX506dUpr165VZmamBg4cqKFDh2rZsmVFfCI4AzkTAAAAzGJ2zmSLWRgffvihRo0apfnz56t169aaPXu2YmJiFBcXp8qVK+d5TWBgoOLi4v6IaSl8tlbowY+/ioyMVGRkZFFvAwAAALilrl27qmvXrnmeMwxDs2fP1gsvvKAePXpIkpYuXarQ0FCtWLFCffr00f79+7VmzRrt3LlTLVq0kCTNnTtX3bp104wZMxQeHm7as6BkkDMBAADgejZz5kwNGTJEAwcOlCTNnz9fq1ev1qJFi/Tcc8/leY3FYlFYWFiR4hZo8GPOnDkFvuGTTz55zZ3xBPfUaywfi6+zuwHAQ716dIWzuwDAQ6Vcsmrdjc7uhetITk522Pf395e/v3+h7xMfH6/ExERFR0fbjwUFBal169baunWr+vTpo61btyo4ONg+8CHlVAt4eXlp+/btuueee679QWAacqaCG3VDW3ImACXmy5Prnd0FAB4s+ZJV5es5uxeuoyB5U0ZGhnbv3q2xY8faj3l5eSk6Olpbt27N994pKSmKjIyU1WrVTTfdpKlTp+qGG24oVP8KNPgxa9asAt3MYrFc91/kAQAAUIwMS85mZjxJERERDocnTJigiRMnFvp2iYmJkqTQ0FCH46GhofZziYmJuUq9fXx8FBISYm8D10fOBAAAAKcwO2eyxVTB8qazZ88qOzs7z5zowIEDed6+fv36WrRokZo0aaKLFy9qxowZuvnmm7Vv3z5Vq1atwN0s0OBHfHx8gW8IAAAAuLvjx48rMDDQvn8tVR+4vpAzAQAA4HpTUnlT27Zt1bZtW/v+zTffrIYNG+qtt97Siy++WOD7FHnNDwAAAKDEGL9vZsZTzuJ6f/4Sf61sc9QmJSWpSpUq9uNJSUmKioqytzl9+rTDdVlZWTp37lyR57gFAAAA4OHMzplsMVWwvKlixYry9vZWUlKSw/GkpKQC5zu+vr5q1qyZDh06VKhuehWqNQAAAIACq1mzpsLCwrR+/R/zjycnJ2v79u32N5natm2rCxcuaPfu3fY2GzZskNVqVevWrU3vMwAAAAAUFz8/PzVv3twhJ7JarVq/fr1DdcfVZGdn68cff3R4oawgqPwAAAAAiiAlJcXhDaT4+Hjt3btXISEhql69ukaOHKkpU6aobt26qlmzpsaNG6fw8HD17NlTktSwYUPdcccdGjJkiObPn6/MzEzFxsaqT58+Cg8Pd9JTAQAAAEDxGDVqlAYMGKAWLVqoVatWmj17tlJTUzVw4EBJUv/+/VW1alVNmzZNkjR58mS1adNGderU0YULF/Tqq6/q2LFjevTRRwsVl8EPAAAAuC4nTXtVGLt27VLnzp3t+6NGjZIkDRgwQEuWLNEzzzyj1NRUDR06VBcuXFD79u21Zs0aBQQE2K95//33FRsbq1tvvVVeXl669957NWfOnCI/DgAAAAAP58RprwrqgQce0JkzZzR+/HglJiYqKipKa9assS+CnpCQIC+vPyapOn/+vIYMGaLExESVL19ezZs315YtW9SoUaNCxWXwAwAAACiCTp06yTDy//ZvsVg0efJkTZ48Od82ISEhWrZsWUl0DwAAAACcLjY2VrGxsXme27hxo8P+rFmzNGvWrCLHvKY1P7799ls9/PDDatu2rU6cOCFJevfdd7V58+YidwgAAACwsRjmb0BxIGcCAACAGZyRM7lL3lTowY9PPvlEMTExKlWqlL7//nulp6dLki5evKipU6cWewcBAAAAwJ2QMwEAAADOV+jBjylTpmj+/PlasGCBfH197cfbtWunPXv2FGvnAAAAAMDdkDMBAAAAzlfoNT/i4uLUoUOHXMeDgoJ04cKF4ugTAAAAkMMNFjwH/oqcCQAAAKZxgwXPnaXQlR9hYWE6dOhQruObN29WrVq1iqVTAAAAAOCuyJkAAAAA5yv04MeQIUM0YsQIbd++XRaLRSdPntT777+vp59+WsOGDSuJPgIAAOB6ZThhA4qInAkAAACmcUbO5CZ5U6GnvXruuedktVp166236vLly+rQoYP8/f319NNPa/jw4SXRRwAAAABwG+RMAAAAgPMVevDDYrHo+eef15gxY3To0CGlpKSoUaNGKlu2bEn0DwAAANcxi5GzmRkPKCpyJgAAAJjF7JzJFtMdFHrww8bPz0+NGjUqzr4AAAAAgMcgZwIAAACcp9CDH507d5bFYsn3/IYNG4rUIQAAAABwZ+RMAAAAgPMVevAjKirKYT8zM1N79+7VTz/9pAEDBhRXvwAAAADJsORsZsYDioicCQAAAKYxO2eyxXQDhR78mDVrVp7HJ06cqJSUlCJ3CAAAAADcGTkTAAAA4HxexXWjhx9+WIsWLSqu2wEAAACS4YQNKCHkTAAAACh2zsiZ3CRvKrbBj61btyogIKC4bgcAAAAAHoWcCQAAADBPoae96tWrl8O+YRg6deqUdu3apXHjxhVbxwAAAADAHZEzAQAAAM5X6MGPoKAgh30vLy/Vr19fkydP1u23315sHQMAAAAsRs5mZjygqMiZAAAAYBazcyZbTHdQqMGP7OxsDRw4UI0bN1b58uVLqk8AAAAA4JbImQAAAADXUKg1P7y9vXX77bfrwoULJdQdAAAA4E9YuA9uhpwJAAAApmLB83wVesHzG2+8UUeOHCmJvgAAAACA2yNnAgAAAJyv0IMfU6ZM0dNPP63PP/9cp06dUnJyssMGAAAAFBvjjzlszdjc5Q0muDZyJgAAAJjG5JzJnfKmAq/5MXnyZI0ePVrdunWTJN19992yWCz284ZhyGKxKDs7u/h7CQAAAAAujpwJAAAAcB0FHvyYNGmSHnvsMX399dcl2R8AAAAAcEvkTAAAAIDrKPDgh2Hk1LJ07NixxDoDAAAAODC7pNpNyrfhmsiZAAAAYDpnTEPlJnlTodb8+HPJNgAAAADAETkTAAAA4BoKXPkhSfXq1fvbL/Pnzp0rUocAAAAAOyo/4GbImQAAAGAqKj/yVajBj0mTJikoKKik+gIAAAAAbo2cCQAAAHANhRr86NOnjypXrlxSfQEAAAAAt0bOBAAAALiGAg9+MHctAAAAzGYxcjYz4wHXipwJAAAAZjM7Z7LFdAcFXvDcMNzkiQAAAADACciZAAAAANdR4MoPq9Vakv0AAAAAALdGzgQAAAC4jgJXfgAAAAAAAAAAALiDQi14DgAAAJjK+H0zMx4AAAAAuAuzcyZbTDdA5QcAAAAAAAAAAPAoDH4AAAAAAAAAAACPwrRXAAAAcFkWI2czMx4AAAAAuAuzcyZbTHdA5QcAAAAAAAAAAPAoVH4AAADAtbnJW0UAAAAA4BTkTHmi8gMAAAAAAAAAAHgUBj8AAAAAAAAAAIBHYdorAAAAuC5D5pZwUy4OAAAAwJ2YnTPZYroBKj8AAAAAAAAAAIBHofIDAAAALsti5GxmxgMAAAAAd2F2zmSL6Q6o/AAAAAAAAAAAAB6Fyg8AAAC4Ltb8AAAAAID8seZHvqj8AAAAAAAAAAAAHoXBDwAAAAAAAAAA4FGY9goAAAAuiwXPAQAAACB/LHiePyo/AAAAAAAAAACAR6HyAwAAAK6LBc8BAAAAIH8seJ4vKj8AAAAAAAAAAIBHYfADAAAAAAAAAAB4FKa9AgAAgOti2isAAAAAyB/TXuWLyg8AAAAAAAAAAOBRqPwAAACAy7IYOZuZ8QAAAADAXZidM9liugMqPwAAAAAAAAAAgEeh8gMAAACuizU/AAAAACB/rPmRLyo/AAAAAAAAAACAR2HwAwAAAAAAAAAAeBSmvQIAAIDrYtorAAAAAMgf017li8oPAAAAAAAAAADgUaj8AAAAgMuyGDmbmfEAAAAAwF2YnTPZYroDKj8AAAAAAAAAAIBHYfADAAAAAAAAAAB4FKa9AgAAgOtiwXMAAAAAyB8LnueLyg8AAAAAAAAAAOBRGPwAAACAy7It3mfmVhjZ2dkaN26catasqVKlSql27dp68cUXZRh/3MgwDI0fP15VqlRRqVKlFB0drV9++aWYPykAAAAA1yNn5EwseA4AAAB4uFdeeUVvvvmmXn/9de3fv1+vvPKKpk+frrlz59rbTJ8+XXPmzNH8+fO1fft2lSlTRjExMUpLS3NizwEAAADAPPPmzVONGjUUEBCg1q1ba8eOHQW67oMPPpDFYlHPnj0LHZPBDwAAALguwwlbIWzZskU9evTQnXfeqRo1aui+++7T7bffbv8ibxiGZs+erRdeeEE9evRQkyZNtHTpUp08eVIrVqy4ts8EAAAAAGyckTMVMm/68MMPNWrUKE2YMEF79uxR06ZNFRMTo9OnT1/1uqNHj+rpp5/WLbfcUriAv2PwAwAAAPiL5ORkhy09PT3PdjfffLPWr1+vgwcPSpJ++OEHbd68WV27dpUkxcfHKzExUdHR0fZrgoKC1Lp1a23durXkHwQAAAAAnGzmzJkaMmSIBg4cqEaNGmn+/PkqXbq0Fi1alO812dnZ6tu3ryZNmqRatWpdU1wGPwAAAIC/iIiIUFBQkH2bNm1anu2ee+459enTRw0aNJCvr6+aNWumkSNHqm/fvpKkxMRESVJoaKjDdaGhofZzAAAAAOCOCvLSWEZGhnbv3u3wQpiXl5eio6Ov+kLY5MmTVblyZQ0ePPia++dzzVcCAAAAJe0aSqqLHE/S8ePHFRgYaD/s7++fZ/P//Oc/ev/997Vs2TLdcMMN2rt3r0aOHKnw8HANGDDAjB4DAAAAuJ6ZnTPZYirnpbE/mzBhgiZOnOhw7OzZs8rOzs7zhbADBw7kefvNmzdr4cKF2rt3b5G6yeAHAAAA8BeBgYEOgx/5GTNmjL36Q5IaN26sY8eOadq0aRowYIDCwsIkSUlJSapSpYr9uqSkJEVFRZVI3wEAAADADAV9aawwLl26pH79+mnBggWqWLFike7F4AcAAABcluX3zcx4hXH58mV5eTnOJOvt7S2r1SpJqlmzpsLCwrR+/Xr7YEdycrK2b9+uYcOGFUOPAQAAAFzPzM6ZbDGlgr00VrFiRXl7eyspKcnheFJSkv1lsT87fPiwjh49qu7du9uP2fIrHx8fxcXFqXbt2gXqJ4MfAAAAwDXq3r27XnrpJVWvXl033HCDvv/+e82cOVODBg2SJFksFo0cOVJTpkxR3bp1VbNmTY0bN07h4eHq2bOnczsPAAAAACXMz89PzZs31/r16+05kNVq1fr16xUbG5urfYMGDfTjjz86HHvhhRd06dIl/etf/8o11dbVMPgBAAAAXKO5c+dq3Lhxevzxx3X69GmFh4frH//4h8aPH29v88wzzyg1NVVDhw7VhQsX1L59e61Zs0YBAQFO7DkAAAAAmGPUqFEaMGCAWrRooVatWmn27NlKTU3VwIEDJUn9+/dX1apVNW3aNAUEBOjGG290uD44OFiSch3/Owx+AAAAwHU5acHzgipXrpxmz56t2bNn59vGYrFo8uTJmjx5ctH6BgAAAAB/5cQFzwvqgQce0JkzZzR+/HglJiYqKipKa9assS+CnpCQkGs64eLA4AcAAAAAAAAAACgxsbGxeU5zJUkbN2686rVLliy5ppgMfgAAAMBlWYyczcx4AAAAAOAuzM6ZbDHdQfHXkgAAAAAAAAAAADgRgx8AAAAAAAAAAMCjMO0VAAAAXJeLL3gOAAAAAE7lBgueOwuVHwAAAAAAAAAAwKNQ+QEAAADX5iZvFQEAAACAU5Az5YnKDwAAAAAAAAAA4FGo/AAAAIDLshg5m5nxAAAAAMBdmJ0z2WK6Ayo/AAAAAAAAAACAR2HwAwAAAAAAAAAAeBSmvQIAAIDrMmTu4n1uUr4NAAAAAJLMz5lsMd0AlR8AAAAAAAAAAMCjUPkBAAAAl8WC5wAAAACQPxY8zx+VHwAAAAAAAAAAwKMw+AEAAAAAAAAAADwK014BAADAdbHgOQAAAADkjwXP80XlBwAAAAAAAAAA8ChUfgAAAMBlseA5AAAAAOSPBc/zR+UHAAAAAAAAAADwKFR+AAAAwHWx5gcAAAAA5I81P/JF5QcAAAAAAAAAAPAoDH4AAAAAAAAAAACPwrRXAAAAcF1MewUAAAAA+WPaq3xR+QEAAAAAAAAAADwKlR8AAABwWRYjZzMzHgAAAAC4C7NzJltMd0DlBwAAAAAAAAAA8CgMfgAAAAAAAAAAAI/CtFcAAABwXSx4DgAAAAD5Y8HzfFH5AQAAAAAAAAAAPAqVHwAAAHBZFsOQxTDvtSIzYwEAAABAUZmdM9liugMqPwAAAAAAAAAAgEeh8gMAAACuizU/AAAAACB/rPmRLyo/AAAAAAAAAACAR2HwAwAAAAAAAAAAeBSmvQIAAIDLshg5m5nxAAAAAMBdmJ0z2WK6Ayo/AAAAAAAAAACAR6HyAwAAAK6LBc8BAAAAIH8seJ4vKj8AAAAAAAAAAIBHYfADAAAAAAAAAAB4FKa9AgAAgMtiwXMAAAAAyB8LnuePyg8AAAAAAAAAAOBRqPwAAACA62LBcwAAAADIHwue54vKDwAAAAAAAAAA4FGo/AAAAIDLYs0PAAAAAMgfa37kj8oPAAAAAAAAAADgURj8AAAAAAAAAAAAHoVprwAAAOC6WPAcAAAAAPLHguf5ovIDAAAAAAAAAAB4FCo/AAAA4NLcZTE9AAAAAHAGcqa8UfkBAAAAAAAAAAA8CoMfAAAAAAAAAADAozDtFQAAAFyXYeRsZsYDAAAAAHdhds5ki+kGnDr40alTJ0VFRWn27NnO7AZQYm5snaL7Hz+juo0vq0JYliYOqqGta4Ls54MrZmrw86fUvOMllQnK1k/bymreC1V1Mt7fib0G4MqObC+njW+H68SPZZR82k8D3orTjTHnHdokHQrQFy9X15HtgcrOsii07hX1f/OgylfNkCSdPeavz1+K1NFd5ZSVYVH9jhfVc+JRlauU6YxHAgBcBTkTPF33R87qvmGnFVIpS0d+LqU3XqiquL2l82wbWS9N/cckqk6TywqLyNT88eFa/n+VTO4xAHezcnFFffxmZZ0746Naja7o8Skn1KDZ5TzbZmVKH8wN1bqPQnQ20VfVaqdr8PMn1bLzJZN7DaA4MO0VUIICSlt1ZF+AXv9ntTzOGpqw6KiqRGZo4sCaeuL2ekr61Vcvf3hY/qWyTe8rAPeQcdlb4Q1T1XNyfJ7nzx7z1xv33aBKtdP02L9/1qg1/1P08BPy9bf+fr2XFvRrKItF+seyn/XEx/uUnWHR4kfry2o180mAgrEY5m8AAHN0vPu8hk44qfdnhumJmHo68nOAXlp2REEV8n4hw7+UVacS/LRoahX9lsREFgD+3sbPgvX2pHD1HZWoeV/GqVajK3r+oVq6cDbvv0OWvFJFX7xXQY9P+VULNh7Qnf3OavLgmjr0YymTew4UnDNyJnfJmxj8AErQrq8D9c70Ktryp2oPm6q1MtSoxWXNfa6aDv5QWr8eDtDc56rJP8BQ53sumN9ZAG6hQecLuuPpX9X4jvN5nl/zaoQadL6gu8YmqOqNl1UxMl033HZeZStmSZLid5XT+V/99cCMw6rS4IqqNLiiB147rF//V0aHtgSa+SgAAOA612voWa1ZFqKvPgxRwi8BmvNsNaVfsSjmwXN5tj/4Q2n934vh+uaz8srMsJjcWwDu6NO3K+mOh35TTJ9ziqyXridf+VX+paz68t8hebZf/0mI+gw/rVa3XlKVyAx1H/CbWnZJ1idvUWUGuCOnD35YrVY988wzCgkJUVhYmCZOnGg/N3PmTDVu3FhlypRRRESEHn/8caWkpNjPL1myRMHBwVqxYoXq1q2rgIAAxcTE6Pjx4/Y2EydOVFRUlN566y1FRESodOnS6t27ty5evChJ2rRpk3x9fZWYmOjQr5EjR+qWW24p2YfHdc3X7/e3sNP/+NJuGBZlZlh0Q8tUZ3ULgBuzWqUDX5dXxZppWtCvgSY2b645PW7UT1+Wt7fJzrDIYpF8/P4o8/D1t8riJR3dyeAHXJDhhA1wMeRM8EQ+vlbVbXJZe74tZz9mGBZ9/205NWqe93Q0AFAYmRkW/fK/0rrplj/+v+jlJTW7JUU/7y6T7zV+/o4l8f4BVu3bUbZE+woUiTNyJjfJm5w++PHOO++oTJky2r59u6ZPn67Jkydr7dq1kiQvLy/NmTNH+/bt0zvvvKMNGzbomWeecbj+8uXLeumll7R06VJ99913unDhgvr06ePQ5tChQ/rPf/6jVatWac2aNfr+++/1+OOPS5I6dOigWrVq6d1337W3z8zM1Pvvv69Bgwbl2+/09HQlJyc7bEBhHD8UoKRffTVo7CmVDcqSj69VvZ84rUrhmQoJZd59AIWXctZX6ane+vrNcNXveEFDlu7XjTHntPSxejq8LecfFqo3S5Ff6Wytfrm6Mq54KeOylz6fGilrtkXJp32d/AQAgLyQM8ETBYZky9tHunDGceqZ82d9VL5SlpN6BcCTJJ/zljXbouC/rG1YvmKmzp/Je9qr5h0v6ZO3K+nEET9ZrdLub8rquy+Cde40U+0B7sjpgx9NmjTRhAkTVLduXfXv318tWrTQ+vXrJeW8SdS5c2fVqFFDXbp00ZQpU/Sf//zH4frMzEy9/vrratu2rZo3b6533nlHW7Zs0Y4dO+xt0tLStHTpUkVFRalDhw6aO3euPvjgA/ubS4MHD9bixYvt7VetWqW0tDT17t07335PmzZNQUFB9i0iIqI4PxZcB7KzLJo8uIaq1k7XJ/v3aeXhH9X05hTtWF9OhpUSbgCFZ/z+5sUNt51Xh0cTVfWGy+ry+Ek1vPW8tr0fKkkqWyFLD8/7RT+vL68XGrXUuMYtdSXZW1VvTJHF6d8KAAB5IWcCAMAcw178VVVrZujRDg11Z2RTvfF8Nd3+wG/kSoCbcvp/uk2aNHHYr1Klik6fPi1JWrdunW699VZVrVpV5cqVU79+/fTbb7/p8uU/SmB9fHzUsmVL+36DBg0UHBys/fv3249Vr15dVatWte+3bdtWVqtVcXFxkqRHHnlEhw4d0rZt2yTllIb37t1bZcrkXQInSWPHjtXFixft25/LxoGCOvRjaT1+W33dU/9GPRh1g57vW0uB5bN1KsHP2V0D4IbKlM+Sl49VoXWvOByvXDtN50/62/frd7iosZv2asLu3Zq4Z5cenHVYFxP9VKF6mtldBv6WxWr+BrgaciZ4ouRz3srOkoL/UuVRvmJWvm9kA0BhBIZky8vb0IUzjhXu58/65lthFlwhWxMXx+uzQ//Tuzt+1v99e0ABZawKq55uRpeBa+KMnMld8ianD374+jr+BWSxWGS1WnX06FHdddddatKkiT755BPt3r1b8+bNkyRlZGQUax8qV66s7t27a/HixUpKStJ///vfq5ZvS5K/v78CAwMdNuBaXb7krYvnfBReM111m17W1i9zL5AOAH/Hx89QRJNUnTkS4HD8THyAylfN/WW9TEiWSgVl69CWQKX+5qtG0Xkvog4AcC5yJniirEwv/fK/0mrW/pL9mMViKKp9in7eXdqJPQPgKXz9DNVtclnfb/5jvQ6rVdq7uawaNb/6Wqt+AYYqVslUdpa0+YtgtY1h6kbAHbns6xS7d++W1WrVa6+9Ji+vnDGav5ZvS1JWVpZ27dqlVq1aSZLi4uJ04cIFNWzY0N4mISFBJ0+eVHh4uCRp27Zt8vLyUv369e1tHn30UT344IOqVq2aateurXbt2pXk4+E6EVA6W+E1/0g8wyIyVOuGK7p0wVtnTvjplrsu6OJvPjp9wlc1G6bpsckntHVNkPZ8U+4qdwVwPUtP9dLZo38Mbpw77q8T+0qrdHCWylfNUMehJ/X+8Lqq1eqSare9qLhvgrV/fXk99sHP9mt2/qeSKte5ojIVMnVsTzmtnBSpWwafUuXaVH7ABZm9mJ6bLNwHSORMcH+fvl1RT88+roM/lFbc96V1z5AzCiht1VcfhEiSxvwrQWcTfbV4WhVJOYukV6+X80KHr6+hClUyVeuGK0pL9dLJo/75xgFw/eo19IxmjKyuek0vq36zy1q+oJLSLnvp9j7nJEnTn6yuimGZGvTPU5KkA3tK62yir2rfcEVnE3313mthMqxS78dPO/MxgKtzxgLkbpI3uezgR506dZSZmam5c+eqe/fu+u677zR//vxc7Xx9fTV8+HDNmTNHPj4+io2NVZs2bexf7CUpICBAAwYM0IwZM5ScnKwnn3xSvXv3VlhYmL1NTEyMAgMDNWXKFE2ePNmUZ4Tnq9f0il795LB9/7FJJyVJX31YXq89VV0hoZn6x8STCq6YpXOnfbTuo/JaNjvUWd0F4AZ+/V9ZzX+wkX1/1ZQakqTm955Rn9cOq/Ed59XrpXh9/Ua4VkysoUq1rqjfmwdVs+Ufb1WeORKgL6ZH6MpFH5Wvlq4usSfUYXCi2Y8CACgicia4u29WlldQhWz1H5Oo8pWydGRfKT3ft6YunM2pdqpUNUPWP02rUSE0S2+uPWjfv3/YGd0/7Ix+2FJGz9xXx+zuA3ADnXrkvHS69NUqOn/GR7VuuKKX3j9in/bqzAk/ef1pXpyMdIveeaWKTiX4qVRpq1remqxn5hxT2aBsJz0BgKJw2cGPpk2baubMmXrllVc0duxYdejQQdOmTVP//v0d2pUuXVrPPvusHnroIZ04cUK33HKLFi5c6NCmTp066tWrl7p166Zz587prrvu0htvvOHQxsvLS4888oimTp2aKwZwrf63taxiwpvme/6zhZX02cJKJvYIgLur3TZZrx7ddtU2rXqfUaveZ/I93+254+r2HPOuA4C7I2eCJ1i5uKJWLq6Y57m/Dmgk/ep31fwKAPLSY9BZ9Rh0Ns9zr35yyGG/SdtULfjmgBndAmACpw5+bNy4MdexFStW2P/81FNP6amnnnI4369fv1zX9OrVS7169bpqrGHDhmnYsGFXbXPixAl169ZNVapUuWo7AAAAmMNi5GxmxgNcCTkTAAAArsbsnMkW0x04fcFzV3Dx4kVt3rxZy5Yt0/Dhw53dHQAAALiREydO6OGHH1aFChVUqlQpNW7cWLt27bKfNwxD48ePV5UqVVSqVClFR0frl19+cWKPgcIjZwIAAIC7YfBDUo8ePXT77bfrscce02233ebs7gAAAMDGMMzfCuH8+fNq166dfH199d///lc///yzXnvtNZUvX97eZvr06ZozZ47mz5+v7du3q0yZMoqJiVFaWlpxf1pAiSFnAgAAcFHOyJkKmTc5i8Uw3KSnLi45OVlBQUHqpB7ysfg6uzsAPNTfrfUAANcq5ZJVt9x4UhcvXlRgYKCzu2P/btXq7hfl4xtgWtyszDTtWDmuwJ/Dc889p++++07ffvttnucNw1B4eLhGjx6tp59+WlLOG/ShoaFasmSJ+vTpU6z9B1wZORMAM3x5cq+zuwDAgyVfsqp8vSMukTc5K2eSCp83OQuVHwAAAHBZtvlrzdyknETiz1t6enqe/Vu5cqVatGih+++/X5UrV1azZs20YMEC+/n4+HglJiYqOjrafiwoKEitW7fW1q1bS/SzAwAAAOD5nJEzXcuaH/PmzVONGjUUEBCg1q1ba8eOHfm2/fTTT9WiRQsFBwerTJkyioqK0rvvvlvomAx+AAAAAH8RERGhoKAg+zZt2rQ82x05ckRvvvmm6tatqy+//FLDhg3Tk08+qXfeeUeSlJiYKEkKDQ11uC40NNR+DgAAAAA82YcffqhRo0ZpwoQJ2rNnj5o2baqYmBidPn06z/YhISF6/vnntXXrVv3vf//TwIEDNXDgQH355ZeFiutTHJ0HAAAAPMnx48cdyrf9/f3zbGe1WtWiRQtNnTpVktSsWTP99NNPmj9/vgYMGGBKXwEAAADAGZKTkx32/f3988ydZs6cqSFDhmjgwIGSpPnz52v16tVatGiRnnvuuVztO3Xq5LA/YsQIvfPOO9q8ebNiYmIK3D8qPwAAAOC6DCdskgIDAx22/AY/qlSpokaNGjkca9iwoRISEiRJYWFhkqSkpCSHNklJSfZzAAAAAHDNnJEz/Z43FaRiPiMjQ7t373aYCtjLy0vR0dEFmgrYMAytX79ecXFx6tChQ2E+GSo/AAAAgGvVrl07xcXFORw7ePCgIiMjJUk1a9ZUWFiY1q9fr6ioKEk5b0dt375dw4YNM7u7AAAAAFBsClIxf/bsWWVnZ+c5FfCBAwfyvffFixdVtWpVpaeny9vbW2+88YZuu+22QvWPwQ8AAAC4rGtdTK8o8Qrjqaee0s0336ypU6eqd+/e2rFjh95++229/fbbOfezWDRy5EhNmTJFdevWVc2aNTVu3DiFh4erZ8+exf8AAAAAAK4rZudMtpjSHxXzJaFcuXLau3evUlJStH79eo0aNUq1atXKNSXW1TD4AQAAAFyjli1bavny5Ro7dqwmT56smjVravbs2erbt6+9zTPPPKPU1FQNHTpUFy5cUPv27bVmzRoFBAQ4secAAAAAUPIqVqwob2/vQk8F7OXlpTp16kiSoqKitH//fk2bNq1Qgx+s+QEAAAAUwV133aUff/xRaWlp2r9/v4YMGeJw3mKxaPLkyUpMTFRaWprWrVunevXqOam3AAAAAGAePz8/NW/eXOvXr7cfs1qtWr9+vdq2bVvg+1itVqWnpxcqNpUfAAAAcF2GkbOZGQ8AAAAA3IXZOZMtZiGMGjVKAwYMUIsWLdSqVSvNnj1bqampGjhwoCSpf//+qlq1qn3B9GnTpqlFixaqXbu20tPT9cUXX+jdd9/Vm2++Wai4DH4AAAAAAAAAAIAS8cADD+jMmTMaP368EhMTFRUVpTVr1tgXQU9ISJCX1x+TVKWmpurxxx/Xr7/+qlKlSqlBgwZ677339MADDxQqLoMfAAAAcFmuvuA5AAAAADiTMxc8L4zY2FjFxsbmeW7jxo0O+1OmTNGUKVOuoWeOWPMDAAAAAAAAAAB4FAY/AAAAAAAAAACAR2HaKwAAALgu4/fNzHgAAAAA4C7MzplsMd0AlR8AAAAAAAAAAMCjUPkBAAAAl8WC5wAAAACQP3dZ8NwZqPwAAAAAAAAAAAAehcoPAAAAuC6rkbOZGQ8AAAAA3IXZOZMtphug8gMAAAAAAAAAAHgUBj8AAAAAAAAAAIBHYdorAAAAuC7j983MeAAAAADgLszOmWwx3QCVHwAAAAAAAAAAwKNQ+QEAAACXZZFkMfGtIot5oQAAAACgyMzOmWwx3QGVHwAAAAAAAAAAwKMw+AEAAAAAAAAAADwK014BAADAdRlGzmZmPAAAAABwF2bnTLaYboDKDwAAAAAAAAAA4FGo/AAAAIDLshgmL3juHi8wAQAAAIAk83MmW0x3QOUHAAAAAAAAAADwKFR+AAAAwHUZv29mxgMAAAAAd2F2zmSL6Qao/AAAAAAAAAAAAB6FwQ8AAAAAAAAAAOBRmPYKAAAALstiGLIY5tVUmxkLAAAAAIrK7JzJFtMdUPkBAAAAAAAAAAA8CpUfAAAAcF3W3zcz4wEAAACAuzA7Z7LFdANUfgAAAAAAAAAAAI/C4AcAAAAAAAAAAPAoTHsFAAAAl8WC5wAAAACQPxY8zx+VHwAAAAAAAAAAwKNQ+QEAAADXZfy+mRkPAAD8f3v3HmVVed4P/DsIw3UGBCsIwUsCCkbQilGpK15RjCbVYEprrIKia1nwAiaVuFIVYxS1lURcKlYNGJdEjQqJJtISU/BCIAmKyxqkwYiQKsS0AqLl5uzfH5Tpb4IYiMOZcw6fz1r7j7PPe/bz7vnjzHnWs5/3BaBSlDpn2hqzAuj8AAAAAAAAqorODwAAyldRbDlKGQ8AAKBSlDpn2hqzAuj8AAAAAAAAqoriBwAAAAAAUFUsewUAQNmqKbYcpYwHAABQKUqdM22NWQl0fgAAAAAAAFVF5wcAAOXLhucAAADbZ8Pz7dL5AQAAAAAAVBXFDwAAAAAAoKpY9goAgLJV07DlKGU8AACASlHqnGlrzEqg8wMAAAAAAKgqOj8AAChfNjwHAADYPhueb5fODwAAAAAAoKro/AAAoHwV/3uUMh4AAEClKHXOtDVmBdD5AQAAAAAAVBXFDwAAAAAAoKpY9goAgLJVUxSpKeFmeqWMBQAA8HGVOmfaGrMS6PwAAAAAAACqis4PAADKV1FsOUoZDwAAoFKUOmfaGrMC6PwAAAAAAACqiuIHAAAAAABQVSx7BQBA+SqSNJQ4HgAAQKUodc60NWYF0PkBAAAAAABUFZ0fAACUrZqiSE0JN9MrZSwAAICPq9Q509aYlUDnBwAAAAAAUFV0fgAAUL6KJKV8qqgyHmACAADYotQ509aYFUDnBwAAAAAAUFUUPwAAAAAAgKpi2SsAAMpXUZR42asK6d8GAABISp8zbY1ZAXR+AAAAAAAAVUXnBwAA5ashSU2J4wEAAFSKUudMW2NWAJ0fAAAAAABAVVH8AAAAAAAAqoriBwAAZaumKEp+fBw33XRTampqMnbs2MZz69evz5gxY9KtW7d06tQpZ511VlatWvUx/zIAAAAtkzN93LypVBQ/AACgGfziF7/I3XffnYEDBzY5P27cuDzxxBP5/ve/n7lz5+bNN9/MsGHDWmiWAAAAuwfFDwAAyldRlP74E6xbty7nnHNO7rnnnuy5556N59esWZP77rsvkyZNyoknnphBgwZl6tSpmTdvXubPn99cfyUAAGB31RI5k84PAACoTGvXrm1ybNiw4SPHjxkzJqeffnqGDBnS5PzChQuzadOmJuf79euXfffdNz/72c92ydwBAABQ/AAAoJy10BNMvXv3TufOnRuPiRMnbneKDz30UF544YUPHbNy5crU1tamS5cuTc537949K1eubNY/FQAAsBuqkM6PO+64I/vvv3/atWuXo446Kj//+c+3O/aee+7JZz/72ey5557Zc889M2TIkI8cvz2td/oTAABQ5VasWJH6+vrG123btt3uuMsvvzyzZ89Ou3btSjU9AACAivHwww/niiuuyJQpU3LUUUfl29/+doYOHZolS5Zk77333mb8nDlzcvbZZ+cv/uIv0q5du9x888055ZRT8sorr6RXr147HFfnBwAA/IH6+vomx/aKHwsXLszvfve7HH744WndunVat26duXPnZvLkyWndunW6d++ejRs3ZvXq1U0+t2rVqvTo0aMEdwIAANCyJk2alIsuuijnn39+Dj744EyZMiUdOnTId77znQ8d/+CDD2b06NE57LDD0q9fv9x7771paGjI008/vVNxdX4AAFC+Sr2Z3k7GOumkk/Lyyy83OXf++eenX79+GT9+fHr37p02bdrk6aefzllnnZUkWbJkSZYvX57Bgwc327QBAIDdVEtsQP6/8dauXdvkdNu2bbd5cGzjxo1ZuHBhrrrqqsZzrVq1ypAhQ3Z4H8T3338/mzZtSteuXXdqmoofAADwJ6qrq8shhxzS5FzHjh3TrVu3xvOjRo3KFVdcka5du6a+vj6XXnppBg8enKOPProlpgwAANAsevfu3eT1tddemwkTJjQ59/vf/z4ffPBBunfv3uR89+7d8+qrr+5QnPHjx6dnz54ZMmTITs1P8QMAgPLVkKSmxPGa2be+9a20atUqZ511VjZs2JChQ4fmzjvvbP5AAADA7qfUOdPWmNnxvRI/jptuuikPPfRQ5syZs9P7LCp+AABAM5ozZ06T1+3atcsdd9yRO+64o2UmBAAAsAts3SPxo+y1117ZY489smrVqibnd2QfxH/6p3/KTTfdlJ/85CcZOHDgTs/PhucAAAAAAECzq62tzaBBg5psVr518/KP2gfxlltuyfXXX59Zs2bliCOO+JNi6/wAAKBs1RRFakq4eV8pYwEAAHxcpc6ZtsbcGVdccUVGjBiRI444IkceeWS+/e1v57333sv555+fJDnvvPPSq1evTJw4MUly880355prrsn06dOz//77Z+XKlUmSTp06pVOnTjscV/EDAAAAAADYJf76r/86b7/9dq655pqsXLkyhx12WGbNmtW4Cfry5cvTqtX/LVJ11113ZePGjfnSl77U5DoftqH6R1H8AACgfBXFlqOU8QAAACpFqXOmrTF30iWXXJJLLrnkQ9/7w30Tly1b9idMalv2/AAAAAAAAKqK4gcAAAAAAFBVLHsFAED5aiiSmhK2cDdY9goAAKggpc6ZtsasADo/AAAAAACAqqLzAwCA8mXDcwAAgO2rkA3PW4LODwAAAAAAoKro/AAAoIyV+immyniCCQAAYIsW6PyokLxJ5wcAAAAAAFBVFD8AAAAAAICqYtkrAADKlw3PAQAAts+G59ul8wMAAAAAAKgqOj8AAChfDUVKupleQ2U8wQQAAJCk9DlTY8zyp/MDAAAAAACoKoofAAAAAABAVbHsFQAA5ato2HKUMh4AAEClKHXOtDVmBdD5AQAAAAAAVBWdHwAAlK+i2HKUMh4AAEClKHXOtDVmBdD5AQAAAAAAVBWdHwAAlK+GIkkJnypqqIwnmAAAAJKUPmdqjFn+dH4AAAAAAABVRfEDAAAAAACoKpa9AgCgfNnwHAAAYPtseL5dOj8AAAAAAICqovMDAIDyVaTEnR+lCwUAAPCxlTpn2hqzAuj8AAAAAAAAqoriBwAAAAAAUFUsewUAQPmy4TkAAMD22fB8u3R+AAAAAAAAVUXnBwAA5auhIUlDieMBAABUiFLnTI0xy5/ODwAAAAAAoKro/AAAoHzZ8wMAAGD77PmxXTo/AAAAAACAqqL4AQAAAAAAVBXLXgEAUL4sewUAALB9lr3aLp0fAAAAAABAVdH5AQBA+WookpTwqaKGyniCCQAAIEnpc6bGmOVP5wcAAAAAAFBVFD8AAAAAAICqYtkrAADKVlE0pCgaShoPAACgUpQ6Z9oasxLo/AAAAAAAAKqKzg8AAMpXUZR2M72iMjbuAwAASFL6nGlrzAqg8wMAAAAAAKgqOj+aSfG/1a7N2ZRURuELqEDr3q2MNRWByvPeui3fL0W5PcFTFCnpj6tyu3+oInImoBTWypmAXWhtOeZNpc6ZGmOWP8WPZvLuu+8mSZ7Lj1t4JkA1++whLT0DoNq9++676dy5c0tPA6hCciagFPY8sKVnAOwO5E2VQfGjmfTs2TMrVqxIXV1dampqWno6VIC1a9emd+/eWbFiRerr61t6OkCV8R3DziqKIu+++2569uzZ0lMBqpSciZ3l9wywq/meYWfJmyqL4kczadWqVT7xiU+09DSoQPX19f7BAruM7xh2Rlk+udTQkNSUcPmKwlIZsKvImfhT+T0D7Gq+Z9gZZZc3lTpnSiomb7LhOQAAAAAAUFV0fgAAUL5seA4AALB9NjzfLp0f0ELatm2ba6+9Nm3btm3pqQBVyHcMAFDp/J4BdjXfM1DdaoqiQso0AADsNtauXZvOnTvnpE5fTuua2pLF3VxszNPrpmfNmjXWfQYAAMpWS+VMSeXkTZa9AgCgbBUNDSlKuHlfUSEb9wEAACSlz5mSysmbLHsFAAAAAABUFZ0fAACULxueAwAAbJ8Nz7dL5weUuZqamsycObOlpwGUwPHHH5+xY8e29DQAACqKnAl2H3ImYGfo/AAAoHw1FEmNzg8AAIAPVeqcKamYvEnnBwAAAAAAUFUUP6CZPfrooxkwYEDat2+fbt26ZciQIXnvvffyi1/8IieffHL22muvdO7cOccdd1xeeOGFJp/99a9/nWOPPTbt2rXLwQcfnNmzZ7fQXQAtpaGhIVdeeWW6du2aHj16ZMKECY3vTZo0KQMGDEjHjh3Tu3fvjB49OuvWrWt8f9q0aenSpUtmzpyZvn37pl27dhk6dGhWrFjROGbChAk57LDDcvfdd6d3797p0KFDhg8fnjVr1iRJnnnmmbRp0yYrV65sMq+xY8fms5/97K69eQBgtyBnAj4OOROwoxQ/oBm99dZbOfvss3PBBRdk8eLFmTNnToYNG5aiKPLuu+9mxIgRee655zJ//vz07ds3p512Wt59990kW/55Dxs2LLW1tVmwYEGmTJmS8ePHt/AdAaV2//33p2PHjlmwYEFuueWWfOMb32hM6lu1apXJkyfnlVdeyf3335+f/vSnufLKK5t8/v33388NN9yQ7373u3n++eezevXq/M3f/E2TMUuXLs0jjzySJ554IrNmzcqLL76Y0aNHJ0mOPfbYfPKTn8wDDzzQOH7Tpk158MEHc8EFF+ziu4cPURRJ0VDCozLatwEqlZwJ+LjkTPAHSp4zVU7eVFMUFTJTqAAvvPBCBg0alGXLlmW//fb7yLENDQ3p0qVLpk+fns9//vP513/915x++ul544030rNnzyTJrFmz8rnPfS4zZszImWeeWYI7AFrS8ccfnw8++CDPPvts47kjjzwyJ554Ym666aZtxj/66KO5+OKL8/vf/z7JlqeYzj///MyfPz9HHXVUkuTVV19N//79s2DBghx55JGZMGFCvvnNb+aNN95Ir169kmz5rjn99NPzn//5n+nRo0duueWWTJs2Lb/61a+SJI8//nhGjBiRlStXpmPHjrv6zwBJkrVr16Zz5845sfav0rqmTcnibi425acbv581a9akvr6+ZHEBdhdyJuDjkDPB/2mpnCmpnLxJ5wc0o0MPPTQnnXRSBgwYkL/6q7/KPffck3feeSdJsmrVqlx00UXp27dvOnfunPr6+qxbty7Lly9PkixevDi9e/du/BGfJIMHD26R+wBazsCBA5u83mefffK73/0uSfKTn/wkJ510Unr16pW6urqce+65+a//+q+8//77jeNbt26dz3zmM42v+/Xrly5dumTx4sWN5/bdd9/GH/HJlu+ahoaGLFmyJEkycuTILF26NPPnz0+yJUEYPny4H/G0iKKhKPkBwK4jZwI+LjkTNNUSOVOl5E2KH9CM9thjj8yePTtPPfVUDj744Nx+++056KCD8vrrr2fEiBFZtGhRbrvttsybNy+LFi1Kt27dsnHjxpaeNlBG2rRp+rRGTU1NGhoasmzZsnz+85/PwIED89hjj2XhwoW54447kqTZv0f23nvvfOELX8jUqVOzatWqPPXUU9q3AYBmIWcCPi45E7CjFD+gmdXU1OSYY47JddddlxdffDG1tbWZMWNGnn/++Vx22WU57bTT8ulPfzpt27ZtbLtMkv79+2fFihV56623Gs9tfYIAYOHChWloaMitt96ao48+OgceeGDefPPNbcZt3rw5v/zlLxtfL1myJKtXr07//v0bzy1fvrzJZ+fPn59WrVrloIMOajx34YUX5uGHH84///M/51Of+lSOOeaYXXRnUNkmTpyYz3zmM6mrq8vee++dM888s/GJwK3Wr1+fMWPGpFu3bunUqVPOOuusrFq1qoVmDNDy5EzAriBnAv6Q4gc0owULFuTGG2/ML3/5yyxfvjyPP/543n777fTv3z99+/bNAw88kMWLF2fBggU555xz0r59+8bPDhkyJAceeGBGjBiRl156Kc8++2y+/vWvt+DdAOWkT58+2bRpU26//fb85je/yQMPPJApU6ZsM65Nmza59NJLs2DBgixcuDAjR47M0UcfnSOPPLJxTLt27Zp811x22WUZPnx4evTo0Thm6NChqa+vzze/+c2cf/75JblH+FAl37ivYaemN3fu3IwZMybz58/P7Nmzs2nTppxyyil57733GseMGzcuTzzxRL7//e9n7ty5efPNNzNs2LDm/ksBVAQ5E7CryJnYbbVEzrSTeVNLUfyAZlRfX59nnnkmp512Wg488MD8wz/8Q2699dZ87nOfy3333Zd33nknhx9+eM4999xcdtll2XvvvRs/26pVq8yYMSP/8z//kyOPPDIXXnhhbrjhhha8G6CcHHrooZk0aVJuvvnmHHLIIXnwwQczceLEbcZ16NAh48ePz5e//OUcc8wx6dSpUx5++OEmY/r06ZNhw4bltNNOyymnnJKBAwfmzjvvbDKmVatWGTlyZD744IOcd955u/TeoJLNmjUrI0eOzKc//ekceuihmTZtWpYvX56FCxcmSdasWZP77rsvkyZNyoknnphBgwZl6tSpmTdvnqeVgd2SnAnYVeRMwB+qKYqiMnYnAQA+0rRp0zJ27NisXr16u2MmTJiQmTNnZtGiRX/0eqNGjcrbb7+dH/7wh803SdhBa9euTefOnXN8zRfTuqbNH/9AM9lcbMqcYkZWrFiR+vr6xvNt27ZN27Zt/+jnly5dmr59++bll1/OIYcckp/+9Kc56aST8s4776RLly6N4/bbb7+MHTs248aN2xW3AQDAh5AzUU1aKmdK/i9vWrNmTZO8qdy0bukJAADlZc2aNXn55Zczffp0P+LZbfXu3bvJ62uvvTYTJkz4yM80NDRk7NixOeaYY3LIIYckSVauXJna2tomhY8k6d69e1auXNmcUwYAoETkTFAZFD8AgCbOOOOM/PznP8/FF1+ck08+uaWnw+6uaEhSwvVk/3ft2g/r/PhjxowZk3//93/Pc889t8umBwBAy5MzUVZKnTM1xix/lr0CAKDsNLZw54zSL3uVH+x0+/Yll1ySH/zgB3nmmWdywAEHNJ637BUAALArtFTOlPzpeVOp6fwAAKBsbc6mpISP6mzOpp0aXxRFLr300syYMSNz5sxpUvhIkkGDBqVNmzZ5+umnc9ZZZyVJlixZkuXLl2fw4MHNNm8AAGD3VOqcqTFmBVD8AACg7NTW1qZHjx55buWPSx67R48eqa2t3aGxY8aMyfTp0/ODH/wgdXV1jft4dO7cOe3bt0/nzp0zatSoXHHFFenatWvq6+tz6aWXZvDgwTn66KN35W0AAABVrCVzpmTn8qaWYtkrAADK0vr167Nx48aSx62trU27du12aGxNTc2Hnp86dWpGjhyZZMt9fOUrX8n3vve9bNiwIUOHDs2dd96ZHj16NNeUAQCA3VBL5UzJzuVNLUXxAwAAAAAAqCqtWnoCAAAAAAAAzUnxA6AZjRw5MmeeeWbj6+OPPz5jx44t+TzmzJmTmpqarF69ertjampqMnPmzB2+5oQJE3LYYYd9rHktW7YsNTU1WbRo0ce6DgAAUJnkTB9NzgTQfBQ/gKo3cuTI1NTUpKamJrW1tenTp0++8Y1vZPPmzbs89uOPP57rr79+h8buyI9vAACA5iZnAqAatW7pCQCUwqmnnpqpU6dmw4YN+fGPf5wxY8akTZs2ueqqq7YZu3HjxtTW1jZL3K5duzbLdQAAAHYlORMA1UbnB7BbaNu2bXr06JH99tsvf/d3f5chQ4bkhz/8YZL/a7u+4YYb0rNnzxx00EFJkhUrVmT48OHp0qVLunbtmjPOOCPLli1rvOYHH3yQK664Il26dEm3bt1y5ZVXpiiKJnH/sIV7w4YNGT9+fHr37p22bdumT58+ue+++7Js2bKccMIJSZI999wzNTU1GTlyZJKkoaEhEydOzAEHHJD27dvn0EMPzaOPPtokzo9//OMceOCBad++fU444YQm89xR48ePz4EHHpgOHTrkk5/8ZK6++ups2rRpm3F33313evfunQ4dOmT48OFZs2ZNk/fvvffe9O/fP+3atUu/fv1y55137vRcAACA0pIz/XFyJoDKovgB7Jbat2+fjRs3Nr5++umns2TJksyePTtPPvlkNm3alKFDh6auri7PPvtsnn/++XTq1Cmnnnpq4+duvfXWTJs2Ld/5znfy3HPP5b//+78zY8aMj4x73nnn5Xvf+14mT56cxYsX5+67706nTp3Su3fvPPbYY0mSJUuW5K233sptt92WJJk4cWK++93vZsqUKXnllVcybty4/O3f/m3mzp2bZEvCMWzYsHzhC1/IokWLcuGFF+ZrX/vaTv9N6urqMm3atPzqV7/KbbfdlnvuuSff+ta3moxZunRpHnnkkTzxxBOZNWtWXnzxxYwePbrx/QcffDDXXHNNbrjhhixevDg33nhjrr766tx///07PR8AAKDlyJm2JWcCqDAFQJUbMWJEccYZZxRFURQNDQ3F7Nmzi7Zt2xZf/epXG9/v3r17sWHDhsbPPPDAA8VBBx1UNDQ0NJ7bsGFD0b59++Jf/uVfiqIoin322ae45ZZbGt/ftGlT8YlPfKIxVlEUxXHHHVdcfvnlRVEUxZIlS4okxezZsz90nv/2b/9WJCneeeedxnPr168vOnToUMybN6/J2FGjRhVnn312URRFcdVVVxUHH3xwk/fHjx+/zbX+UJJixowZ233/H//xH4tBgwY1vr722muLPfbYo/jtb3/beO6pp54qWrVqVbz11ltFURTFpz71qWL69OlNrnP99dcXgwcPLoqiKF5//fUiSfHiiy9uNy4AAFBacqYPJ2cCqGz2/AB2C08++WQ6deqUTZs2paGhIV/+8pczYcKExvcHDBjQZM3al156KUuXLk1dXV2T66xfvz6vvfZa1qxZk7feeitHHXVU43utW7fOEUccsU0b91aLFi3KHnvskeOOO26H57106dK8//77Ofnkk5uc37hxY/78z/88SbJ48eIm80iSwYMH73CMrR5++OFMnjw5r732WtatW5fNmzenvr6+yZh99903vXr1ahKnoaEhS5YsSV1dXV577bWMGjUqF110UeOYzZs3p3Pnzjs9HwAAoHTkTH+cnAmgsih+ALuFE044IXfddVdqa2vTs2fPtG7d9OuvY8eOTV6vW7cugwYNyoMPPrjNtf7sz/7sT5pD+/btd/oz69atS5L86Ec/avIDOtmyJm9z+dnPfpZzzjkn1113XYYOHZrOnTvnoYceyq233rrTc73nnnu2SSz22GOPZpsrAADQ/ORMH03OBFB5FD+A3ULHjh3Tp0+fHR5/+OGH5+GHH87ee++9zZM8W+2zzz5ZsGBBjj322CRbntZZuHBhDj/88A8dP2DAgDQ0NGTu3LkZMmTINu9vfYrqgw8+aDx38MEHp23btlm+fPl2n37q379/40aEW82fP/+P3+T/Z968edlvv/3y9a9/vfHcG2+8sc245cuX580330zPnj0b47Rq1SoHHXRQunfvnp49e+Y3v/lNzjnnnJ2KDwAAtCw500eTMwFUHhueA3yIc845J3vttVfOOOOMPPvss3n99dczZ86cXHbZZfntb3+bJLn88stz0003ZebMmXn11VczevTorF69ervX3H///TNixIhccMEFmTlzZuM1H3nkkSTJfvvtl5qamjz55JN5++23s27dutTV1eWrX/1qxo0bl/vvvz+vvfZaXnjhhdx+++2NG+JdfPHF+fWvf52///u/z5IlSzJ9+vRMmzZtp+63b9++Wb58eR566KG89tprmTx58oduRNiuXbuMGDEiL730Up599tlcdtllGT58eHr06JEkue666zJx4sRMnjw5//Ef/5GXX345U6dOzaRJk3ZqPgAAQHmTM8mZAMqd4gfAh+jQoUOeeeaZ7Lvvvhk2bFj69++fUaNGZf369Y1PNX3lK1/JueeemxEjRmTw4MGpq6vLF7/4xY+87l133ZUvfelLGT16dPr165eLLroo7733XpKkV69eue666/K1r30t3bt3zyWXXJIkuf7663P11Vdn4sSJ6d+/f0499dT86Ec/ygEHHJBky5qyjz32WGbOnJlDDz00U6ZMyY033rhT9/uXf/mXGTduXC655JIcdthhmTdvXq6++uptxvXp0yfDhg3LaaedllNOOSUDBw7MnXfe2fj+hRdemHvvvTdTp07NgAEDctxxx2XatGmNcwUAAKqDnEnOBFDuaort7TIFAAAAAABQgXR+AAAAAAAAVUXxAwAAAAAAqCqKHwAAAAAAQFVR/AAAAAAAAKqK4gcAAAAAAFBVFD8AAAAAAICqovgBAAAAAABUFcUPAAAAAACgqih+AAAAAAAAVUXxAwAAAAAAqCqKHwAAAAAAQFX5fzviJ5VBHdaAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the confusion matrix\n",
    "confusion_matrix(y_te, prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
